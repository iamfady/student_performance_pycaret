2024-08-31 22:01:17,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 22:01:17,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 22:01:17,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 22:01:17,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 22:38:13,618:INFO:PyCaret ClassificationExperiment
2024-08-31 22:38:13,619:INFO:Logging name: clf-default-name
2024-08-31 22:38:13,619:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-31 22:38:13,619:INFO:version 3.3.2
2024-08-31 22:38:13,619:INFO:Initializing setup()
2024-08-31 22:38:13,619:INFO:self.USI: faa2
2024-08-31 22:38:13,619:INFO:self._variable_keys: {'memory', 'gpu_param', 'log_plots_param', 'fold_generator', 'logging_param', 'target_param', 'y', 'fix_imbalance', 'exp_name_log', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'data', 'X_train', 'is_multiclass', 'exp_id', 'y_train', 'fold_shuffle_param', 'fold_groups_param', 'y_test', '_ml_usecase', 'idx', 'seed', 'USI', 'html_param', '_available_plots', 'X', 'X_test'}
2024-08-31 22:38:13,619:INFO:Checking environment
2024-08-31 22:38:13,619:INFO:python_version: 3.11.5
2024-08-31 22:38:13,620:INFO:python_build: ('main', 'Sep 11 2023 08:17:37')
2024-08-31 22:38:13,620:INFO:machine: arm64
2024-08-31 22:38:13,620:INFO:platform: macOS-13.2.1-arm64-arm-64bit
2024-08-31 22:38:13,620:INFO:Memory: svmem(total=8589934592, available=2581823488, percent=69.9, used=3362471936, free=663240704, active=1937375232, inactive=1886191616, wired=1425096704)
2024-08-31 22:38:13,620:INFO:Physical Core: 8
2024-08-31 22:38:13,620:INFO:Logical Core: 8
2024-08-31 22:38:13,620:INFO:Checking libraries
2024-08-31 22:38:13,620:INFO:System:
2024-08-31 22:38:13,621:INFO:    python: 3.11.5 (main, Sep 11 2023, 08:17:37) [Clang 14.0.6 ]
2024-08-31 22:38:13,621:INFO:executable: /Users/fady/anaconda3/bin/python
2024-08-31 22:38:13,621:INFO:   machine: macOS-13.2.1-arm64-arm-64bit
2024-08-31 22:38:13,621:INFO:PyCaret required dependencies:
2024-08-31 22:38:14,526:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:38:15,411:INFO:                 pip: 23.2.1
2024-08-31 22:38:15,411:INFO:          setuptools: 68.0.0
2024-08-31 22:38:15,411:INFO:             pycaret: 3.3.2
2024-08-31 22:38:15,411:INFO:             IPython: 8.20.0
2024-08-31 22:38:15,411:INFO:          ipywidgets: 8.1.2
2024-08-31 22:38:15,411:INFO:                tqdm: 4.65.0
2024-08-31 22:38:15,411:INFO:               numpy: 1.26.4
2024-08-31 22:38:15,411:INFO:              pandas: 1.5.3
2024-08-31 22:38:15,411:INFO:              jinja2: 3.0.3
2024-08-31 22:38:15,411:INFO:               scipy: 1.10.0
2024-08-31 22:38:15,411:INFO:              joblib: 1.2.0
2024-08-31 22:38:15,411:INFO:             sklearn: 1.4.2
2024-08-31 22:38:15,411:INFO:                pyod: 2.0.1
2024-08-31 22:38:15,411:INFO:            imblearn: 0.12.3
2024-08-31 22:38:15,411:INFO:   category_encoders: 2.6.3
2024-08-31 22:38:15,411:INFO:            lightgbm: 4.5.0
2024-08-31 22:38:15,411:INFO:               numba: 0.59.0
2024-08-31 22:38:15,411:INFO:            requests: 2.31.0
2024-08-31 22:38:15,411:INFO:          matplotlib: 3.7.5
2024-08-31 22:38:15,411:INFO:          scikitplot: 0.3.7
2024-08-31 22:38:15,411:INFO:         yellowbrick: 1.5
2024-08-31 22:38:15,411:INFO:              plotly: 5.19.0
2024-08-31 22:38:15,411:INFO:    plotly-resampler: Not installed
2024-08-31 22:38:15,411:INFO:             kaleido: 0.2.1
2024-08-31 22:38:15,411:INFO:           schemdraw: 0.15
2024-08-31 22:38:15,411:INFO:         statsmodels: 0.14.0
2024-08-31 22:38:15,411:INFO:              sktime: 0.26.0
2024-08-31 22:38:15,411:INFO:               tbats: 1.1.3
2024-08-31 22:38:15,411:INFO:            pmdarima: 2.0.4
2024-08-31 22:38:15,411:INFO:              psutil: 5.9.0
2024-08-31 22:38:15,411:INFO:          markupsafe: 2.1.3
2024-08-31 22:38:15,411:INFO:             pickle5: Not installed
2024-08-31 22:38:15,411:INFO:         cloudpickle: 2.2.1
2024-08-31 22:38:15,411:INFO:         deprecation: 2.1.0
2024-08-31 22:38:15,411:INFO:              xxhash: 2.0.2
2024-08-31 22:38:15,411:INFO:           wurlitzer: 3.0.2
2024-08-31 22:38:15,411:INFO:PyCaret optional dependencies:
2024-08-31 22:38:15,525:INFO:                shap: Not installed
2024-08-31 22:38:15,526:INFO:           interpret: Not installed
2024-08-31 22:38:15,526:INFO:                umap: Not installed
2024-08-31 22:38:15,526:INFO:     ydata_profiling: Not installed
2024-08-31 22:38:15,526:INFO:  explainerdashboard: Not installed
2024-08-31 22:38:15,526:INFO:             autoviz: Not installed
2024-08-31 22:38:15,526:INFO:           fairlearn: Not installed
2024-08-31 22:38:15,526:INFO:          deepchecks: Not installed
2024-08-31 22:38:15,526:INFO:             xgboost: 2.0.3
2024-08-31 22:38:15,526:INFO:            catboost: 1.2
2024-08-31 22:38:15,526:INFO:              kmodes: Not installed
2024-08-31 22:38:15,526:INFO:             mlxtend: Not installed
2024-08-31 22:38:15,526:INFO:       statsforecast: Not installed
2024-08-31 22:38:15,526:INFO:        tune_sklearn: Not installed
2024-08-31 22:38:15,526:INFO:                 ray: Not installed
2024-08-31 22:38:15,526:INFO:            hyperopt: Not installed
2024-08-31 22:38:15,526:INFO:              optuna: Not installed
2024-08-31 22:38:15,526:INFO:               skopt: Not installed
2024-08-31 22:38:15,526:INFO:              mlflow: Not installed
2024-08-31 22:38:15,526:INFO:              gradio: Not installed
2024-08-31 22:38:15,526:INFO:             fastapi: Not installed
2024-08-31 22:38:15,526:INFO:             uvicorn: Not installed
2024-08-31 22:38:15,526:INFO:              m2cgen: Not installed
2024-08-31 22:38:15,526:INFO:           evidently: Not installed
2024-08-31 22:38:15,526:INFO:               fugue: Not installed
2024-08-31 22:38:15,526:INFO:           streamlit: Not installed
2024-08-31 22:38:15,526:INFO:             prophet: Not installed
2024-08-31 22:38:15,526:INFO:None
2024-08-31 22:38:15,526:INFO:Set up data.
2024-08-31 22:38:15,532:INFO:Set up folding strategy.
2024-08-31 22:38:15,532:INFO:Set up train/test split.
2024-08-31 22:38:15,536:INFO:Set up index.
2024-08-31 22:38:15,536:INFO:Assigning column types.
2024-08-31 22:38:15,537:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-31 22:38:15,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 22:38:15,563:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:38:15,578:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:15,579:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 22:38:16,422:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:38:16,436:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,437:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,437:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-31 22:38:16,456:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:38:16,466:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,467:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:38:16,493:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,494:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,495:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-31 22:38:16,521:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,522:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,548:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,549:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,551:INFO:Preparing preprocessing pipeline...
2024-08-31 22:38:16,553:INFO:Set up simple imputation.
2024-08-31 22:38:16,554:INFO:Set up encoding of ordinal features.
2024-08-31 22:38:16,555:INFO:Set up encoding of categorical features.
2024-08-31 22:38:16,591:INFO:Finished creating preprocessing pipeline.
2024-08-31 22:38:16,617:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-31 22:38:16,617:INFO:Creating final display dataframe.
2024-08-31 22:38:16,694:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        GradeClass
2                   Target type        Multiclass
3           Original data shape        (2392, 15)
4        Transformed data shape        (2392, 25)
5   Transformed train set shape        (1674, 25)
6    Transformed test set shape         (718, 25)
7               Ignore features                 1
8              Numeric features                 3
9          Categorical features                 9
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              faa2
2024-08-31 22:38:16,724:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,726:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,754:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:38:16,755:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:38:16,756:INFO:setup() successfully completed in 3.14s...............
2024-08-31 22:38:58,831:INFO:Initializing compare_models()
2024-08-31 22:38:58,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-31 22:38:58,832:INFO:Checking exceptions
2024-08-31 22:38:58,838:INFO:Preparing display monitor
2024-08-31 22:38:58,881:INFO:Initializing Logistic Regression
2024-08-31 22:38:58,881:INFO:Total runtime is 5.916754404703776e-06 minutes
2024-08-31 22:38:58,883:INFO:SubProcess create_model() called ==================================
2024-08-31 22:38:58,884:INFO:Initializing create_model()
2024-08-31 22:38:58,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:38:58,884:INFO:Checking exceptions
2024-08-31 22:38:58,884:INFO:Importing libraries
2024-08-31 22:38:58,885:INFO:Copying training dataset
2024-08-31 22:38:58,888:INFO:Defining folds
2024-08-31 22:38:58,888:INFO:Declaring metric variables
2024-08-31 22:38:58,889:INFO:Importing untrained model
2024-08-31 22:38:58,891:INFO:Logistic Regression Imported successfully
2024-08-31 22:38:58,894:INFO:Starting cross validation
2024-08-31 22:38:58,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:00,995:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,001:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,003:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,008:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,011:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,016:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,031:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,039:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 22:39:01,573:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,574:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,592:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,592:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,611:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,613:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,626:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,626:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,627:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,632:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,639:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,639:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,643:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,649:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,650:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,654:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,865:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,877:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,882:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:39:01,893:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:01,897:INFO:Calculating mean and std
2024-08-31 22:39:01,898:INFO:Creating metrics dataframe
2024-08-31 22:39:01,900:INFO:Uploading results into container
2024-08-31 22:39:01,901:INFO:Uploading model into container now
2024-08-31 22:39:01,901:INFO:_master_model_container: 1
2024-08-31 22:39:01,901:INFO:_display_container: 2
2024-08-31 22:39:01,901:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 22:39:01,901:INFO:create_model() successfully completed......................................
2024-08-31 22:39:01,990:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:01,990:INFO:Creating metrics dataframe
2024-08-31 22:39:01,994:INFO:Initializing K Neighbors Classifier
2024-08-31 22:39:01,994:INFO:Total runtime is 0.05188441276550293 minutes
2024-08-31 22:39:01,995:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:01,995:INFO:Initializing create_model()
2024-08-31 22:39:01,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:01,995:INFO:Checking exceptions
2024-08-31 22:39:01,995:INFO:Importing libraries
2024-08-31 22:39:01,995:INFO:Copying training dataset
2024-08-31 22:39:01,997:INFO:Defining folds
2024-08-31 22:39:01,997:INFO:Declaring metric variables
2024-08-31 22:39:01,998:INFO:Importing untrained model
2024-08-31 22:39:01,999:INFO:K Neighbors Classifier Imported successfully
2024-08-31 22:39:02,001:INFO:Starting cross validation
2024-08-31 22:39:02,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:02,073:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,074:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,082:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,089:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,092:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,101:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,113:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,118:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,125:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,126:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,128:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,133:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,140:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,142:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,144:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,147:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,152:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,154:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,157:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,158:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,160:INFO:Calculating mean and std
2024-08-31 22:39:02,160:INFO:Creating metrics dataframe
2024-08-31 22:39:02,162:INFO:Uploading results into container
2024-08-31 22:39:02,162:INFO:Uploading model into container now
2024-08-31 22:39:02,162:INFO:_master_model_container: 2
2024-08-31 22:39:02,162:INFO:_display_container: 2
2024-08-31 22:39:02,162:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 22:39:02,162:INFO:create_model() successfully completed......................................
2024-08-31 22:39:02,233:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-31 22:39:02,236:WARNING:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-08-31 22:39:02,236:INFO:Initializing create_model()
2024-08-31 22:39:02,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:02,236:INFO:Checking exceptions
2024-08-31 22:39:02,236:INFO:Importing libraries
2024-08-31 22:39:02,236:INFO:Copying training dataset
2024-08-31 22:39:02,237:INFO:Defining folds
2024-08-31 22:39:02,237:INFO:Declaring metric variables
2024-08-31 22:39:02,238:INFO:Importing untrained model
2024-08-31 22:39:02,239:INFO:K Neighbors Classifier Imported successfully
2024-08-31 22:39:02,242:INFO:Starting cross validation
2024-08-31 22:39:02,242:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:02,317:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,324:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,325:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,326:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,329:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,330:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,331:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,334:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,334:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,337:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,338:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,341:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,341:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,343:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,346:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,348:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,379:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,379:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,383:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,384:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:39:02,384:INFO:Calculating mean and std
2024-08-31 22:39:02,385:INFO:Creating metrics dataframe
2024-08-31 22:39:02,386:INFO:Uploading results into container
2024-08-31 22:39:02,386:INFO:Uploading model into container now
2024-08-31 22:39:02,387:INFO:_master_model_container: 3
2024-08-31 22:39:02,387:INFO:_display_container: 2
2024-08-31 22:39:02,387:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 22:39:02,387:INFO:create_model() successfully completed......................................
2024-08-31 22:39:02,454:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2024-08-31 22:39:02,454:ERROR:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-08-31 22:39:02,454:INFO:Initializing Naive Bayes
2024-08-31 22:39:02,454:INFO:Total runtime is 0.05955622990926107 minutes
2024-08-31 22:39:02,455:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:02,455:INFO:Initializing create_model()
2024-08-31 22:39:02,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:02,455:INFO:Checking exceptions
2024-08-31 22:39:02,455:INFO:Importing libraries
2024-08-31 22:39:02,455:INFO:Copying training dataset
2024-08-31 22:39:02,457:INFO:Defining folds
2024-08-31 22:39:02,457:INFO:Declaring metric variables
2024-08-31 22:39:02,458:INFO:Importing untrained model
2024-08-31 22:39:02,459:INFO:Naive Bayes Imported successfully
2024-08-31 22:39:02,461:INFO:Starting cross validation
2024-08-31 22:39:02,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:02,546:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,546:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,564:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,564:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,566:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,572:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,572:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,573:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,603:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,603:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:02,606:INFO:Calculating mean and std
2024-08-31 22:39:02,607:INFO:Creating metrics dataframe
2024-08-31 22:39:02,608:INFO:Uploading results into container
2024-08-31 22:39:02,608:INFO:Uploading model into container now
2024-08-31 22:39:02,608:INFO:_master_model_container: 4
2024-08-31 22:39:02,608:INFO:_display_container: 2
2024-08-31 22:39:02,609:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-31 22:39:02,609:INFO:create_model() successfully completed......................................
2024-08-31 22:39:02,675:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:02,675:INFO:Creating metrics dataframe
2024-08-31 22:39:02,679:INFO:Initializing Decision Tree Classifier
2024-08-31 22:39:02,679:INFO:Total runtime is 0.06330688397089641 minutes
2024-08-31 22:39:02,680:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:02,681:INFO:Initializing create_model()
2024-08-31 22:39:02,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:02,681:INFO:Checking exceptions
2024-08-31 22:39:02,681:INFO:Importing libraries
2024-08-31 22:39:02,681:INFO:Copying training dataset
2024-08-31 22:39:02,682:INFO:Defining folds
2024-08-31 22:39:02,682:INFO:Declaring metric variables
2024-08-31 22:39:02,683:INFO:Importing untrained model
2024-08-31 22:39:02,684:INFO:Decision Tree Classifier Imported successfully
2024-08-31 22:39:02,686:INFO:Starting cross validation
2024-08-31 22:39:02,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:02,843:INFO:Calculating mean and std
2024-08-31 22:39:02,843:INFO:Creating metrics dataframe
2024-08-31 22:39:02,844:INFO:Uploading results into container
2024-08-31 22:39:02,845:INFO:Uploading model into container now
2024-08-31 22:39:02,845:INFO:_master_model_container: 5
2024-08-31 22:39:02,845:INFO:_display_container: 2
2024-08-31 22:39:02,845:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-31 22:39:02,845:INFO:create_model() successfully completed......................................
2024-08-31 22:39:02,916:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:02,916:INFO:Creating metrics dataframe
2024-08-31 22:39:02,920:INFO:Initializing SVM - Linear Kernel
2024-08-31 22:39:02,920:INFO:Total runtime is 0.06732503175735474 minutes
2024-08-31 22:39:02,921:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:02,922:INFO:Initializing create_model()
2024-08-31 22:39:02,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:02,922:INFO:Checking exceptions
2024-08-31 22:39:02,922:INFO:Importing libraries
2024-08-31 22:39:02,922:INFO:Copying training dataset
2024-08-31 22:39:02,923:INFO:Defining folds
2024-08-31 22:39:02,923:INFO:Declaring metric variables
2024-08-31 22:39:02,924:INFO:Importing untrained model
2024-08-31 22:39:02,925:INFO:SVM - Linear Kernel Imported successfully
2024-08-31 22:39:02,927:INFO:Starting cross validation
2024-08-31 22:39:02,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:03,055:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,056:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,056:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,058:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,058:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,061:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,065:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,072:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,075:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,076:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,079:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,082:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,088:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,089:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,097:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,098:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,130:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,134:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,136:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,138:INFO:Calculating mean and std
2024-08-31 22:39:03,138:INFO:Creating metrics dataframe
2024-08-31 22:39:03,139:INFO:Uploading results into container
2024-08-31 22:39:03,140:INFO:Uploading model into container now
2024-08-31 22:39:03,140:INFO:_master_model_container: 6
2024-08-31 22:39:03,140:INFO:_display_container: 2
2024-08-31 22:39:03,140:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-31 22:39:03,140:INFO:create_model() successfully completed......................................
2024-08-31 22:39:03,210:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:03,210:INFO:Creating metrics dataframe
2024-08-31 22:39:03,214:INFO:Initializing Ridge Classifier
2024-08-31 22:39:03,214:INFO:Total runtime is 0.07223099867502848 minutes
2024-08-31 22:39:03,216:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:03,216:INFO:Initializing create_model()
2024-08-31 22:39:03,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:03,216:INFO:Checking exceptions
2024-08-31 22:39:03,216:INFO:Importing libraries
2024-08-31 22:39:03,216:INFO:Copying training dataset
2024-08-31 22:39:03,217:INFO:Defining folds
2024-08-31 22:39:03,217:INFO:Declaring metric variables
2024-08-31 22:39:03,218:INFO:Importing untrained model
2024-08-31 22:39:03,219:INFO:Ridge Classifier Imported successfully
2024-08-31 22:39:03,222:INFO:Starting cross validation
2024-08-31 22:39:03,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:03,303:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,306:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,307:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,307:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,310:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,311:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,312:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,314:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,316:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,317:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,324:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,326:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,340:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,341:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,352:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,353:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,367:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,368:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,368:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:03,370:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:03,372:INFO:Calculating mean and std
2024-08-31 22:39:03,372:INFO:Creating metrics dataframe
2024-08-31 22:39:03,373:INFO:Uploading results into container
2024-08-31 22:39:03,373:INFO:Uploading model into container now
2024-08-31 22:39:03,374:INFO:_master_model_container: 7
2024-08-31 22:39:03,374:INFO:_display_container: 2
2024-08-31 22:39:03,374:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-31 22:39:03,374:INFO:create_model() successfully completed......................................
2024-08-31 22:39:03,445:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:03,445:INFO:Creating metrics dataframe
2024-08-31 22:39:03,449:INFO:Initializing Random Forest Classifier
2024-08-31 22:39:03,449:INFO:Total runtime is 0.07614311377207438 minutes
2024-08-31 22:39:03,450:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:03,450:INFO:Initializing create_model()
2024-08-31 22:39:03,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:03,451:INFO:Checking exceptions
2024-08-31 22:39:03,451:INFO:Importing libraries
2024-08-31 22:39:03,451:INFO:Copying training dataset
2024-08-31 22:39:03,452:INFO:Defining folds
2024-08-31 22:39:03,452:INFO:Declaring metric variables
2024-08-31 22:39:03,453:INFO:Importing untrained model
2024-08-31 22:39:03,455:INFO:Random Forest Classifier Imported successfully
2024-08-31 22:39:03,457:INFO:Starting cross validation
2024-08-31 22:39:03,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:03,893:INFO:Calculating mean and std
2024-08-31 22:39:03,894:INFO:Creating metrics dataframe
2024-08-31 22:39:03,895:INFO:Uploading results into container
2024-08-31 22:39:03,895:INFO:Uploading model into container now
2024-08-31 22:39:03,895:INFO:_master_model_container: 8
2024-08-31 22:39:03,895:INFO:_display_container: 2
2024-08-31 22:39:03,896:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-31 22:39:03,896:INFO:create_model() successfully completed......................................
2024-08-31 22:39:03,963:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:03,964:INFO:Creating metrics dataframe
2024-08-31 22:39:03,968:INFO:Initializing Quadratic Discriminant Analysis
2024-08-31 22:39:03,968:INFO:Total runtime is 0.08478551705678303 minutes
2024-08-31 22:39:03,969:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:03,969:INFO:Initializing create_model()
2024-08-31 22:39:03,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:03,969:INFO:Checking exceptions
2024-08-31 22:39:03,969:INFO:Importing libraries
2024-08-31 22:39:03,969:INFO:Copying training dataset
2024-08-31 22:39:03,971:INFO:Defining folds
2024-08-31 22:39:03,971:INFO:Declaring metric variables
2024-08-31 22:39:03,972:INFO:Importing untrained model
2024-08-31 22:39:03,973:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-31 22:39:03,974:INFO:Starting cross validation
2024-08-31 22:39:03,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:04,026:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,026:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,031:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,044:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,047:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,051:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,059:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,063:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,063:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,065:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,077:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,078:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,089:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,096:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,097:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,100:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,110:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:39:04,113:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,113:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,123:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,126:INFO:Calculating mean and std
2024-08-31 22:39:04,127:INFO:Creating metrics dataframe
2024-08-31 22:39:04,128:INFO:Uploading results into container
2024-08-31 22:39:04,128:INFO:Uploading model into container now
2024-08-31 22:39:04,128:INFO:_master_model_container: 9
2024-08-31 22:39:04,128:INFO:_display_container: 2
2024-08-31 22:39:04,128:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-31 22:39:04,129:INFO:create_model() successfully completed......................................
2024-08-31 22:39:04,203:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:04,203:INFO:Creating metrics dataframe
2024-08-31 22:39:04,207:INFO:Initializing Ada Boost Classifier
2024-08-31 22:39:04,207:INFO:Total runtime is 0.08877505064010618 minutes
2024-08-31 22:39:04,208:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:04,209:INFO:Initializing create_model()
2024-08-31 22:39:04,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:04,209:INFO:Checking exceptions
2024-08-31 22:39:04,209:INFO:Importing libraries
2024-08-31 22:39:04,209:INFO:Copying training dataset
2024-08-31 22:39:04,210:INFO:Defining folds
2024-08-31 22:39:04,210:INFO:Declaring metric variables
2024-08-31 22:39:04,211:INFO:Importing untrained model
2024-08-31 22:39:04,212:INFO:Ada Boost Classifier Imported successfully
2024-08-31 22:39:04,214:INFO:Starting cross validation
2024-08-31 22:39:04,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:04,263:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,268:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,283:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,286:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,291:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,295:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,327:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,332:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,369:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,375:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,389:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,392:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,394:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,397:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,410:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,411:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,422:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:39:04,424:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,478:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,489:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:04,492:INFO:Calculating mean and std
2024-08-31 22:39:04,492:INFO:Creating metrics dataframe
2024-08-31 22:39:04,493:INFO:Uploading results into container
2024-08-31 22:39:04,493:INFO:Uploading model into container now
2024-08-31 22:39:04,494:INFO:_master_model_container: 10
2024-08-31 22:39:04,494:INFO:_display_container: 2
2024-08-31 22:39:04,494:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-08-31 22:39:04,494:INFO:create_model() successfully completed......................................
2024-08-31 22:39:04,559:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:04,559:INFO:Creating metrics dataframe
2024-08-31 22:39:04,563:INFO:Initializing Gradient Boosting Classifier
2024-08-31 22:39:04,563:INFO:Total runtime is 0.09470510085423786 minutes
2024-08-31 22:39:04,564:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:04,564:INFO:Initializing create_model()
2024-08-31 22:39:04,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:04,564:INFO:Checking exceptions
2024-08-31 22:39:04,564:INFO:Importing libraries
2024-08-31 22:39:04,564:INFO:Copying training dataset
2024-08-31 22:39:04,566:INFO:Defining folds
2024-08-31 22:39:04,566:INFO:Declaring metric variables
2024-08-31 22:39:04,567:INFO:Importing untrained model
2024-08-31 22:39:04,568:INFO:Gradient Boosting Classifier Imported successfully
2024-08-31 22:39:04,569:INFO:Starting cross validation
2024-08-31 22:39:04,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:05,674:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,687:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,696:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,700:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,705:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,716:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,717:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:05,722:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,491:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,502:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,505:INFO:Calculating mean and std
2024-08-31 22:39:06,506:INFO:Creating metrics dataframe
2024-08-31 22:39:06,507:INFO:Uploading results into container
2024-08-31 22:39:06,507:INFO:Uploading model into container now
2024-08-31 22:39:06,508:INFO:_master_model_container: 11
2024-08-31 22:39:06,508:INFO:_display_container: 2
2024-08-31 22:39:06,508:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-31 22:39:06,508:INFO:create_model() successfully completed......................................
2024-08-31 22:39:06,574:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:06,574:INFO:Creating metrics dataframe
2024-08-31 22:39:06,578:INFO:Initializing Linear Discriminant Analysis
2024-08-31 22:39:06,578:INFO:Total runtime is 0.1282845616340637 minutes
2024-08-31 22:39:06,579:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:06,579:INFO:Initializing create_model()
2024-08-31 22:39:06,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:06,579:INFO:Checking exceptions
2024-08-31 22:39:06,579:INFO:Importing libraries
2024-08-31 22:39:06,579:INFO:Copying training dataset
2024-08-31 22:39:06,581:INFO:Defining folds
2024-08-31 22:39:06,581:INFO:Declaring metric variables
2024-08-31 22:39:06,582:INFO:Importing untrained model
2024-08-31 22:39:06,582:INFO:Linear Discriminant Analysis Imported successfully
2024-08-31 22:39:06,584:INFO:Starting cross validation
2024-08-31 22:39:06,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:06,655:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,665:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,675:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,683:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,696:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,698:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,701:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,710:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,727:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,740:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:39:06,741:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:06,743:INFO:Calculating mean and std
2024-08-31 22:39:06,743:INFO:Creating metrics dataframe
2024-08-31 22:39:06,745:INFO:Uploading results into container
2024-08-31 22:39:06,745:INFO:Uploading model into container now
2024-08-31 22:39:06,745:INFO:_master_model_container: 12
2024-08-31 22:39:06,745:INFO:_display_container: 2
2024-08-31 22:39:06,745:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-31 22:39:06,745:INFO:create_model() successfully completed......................................
2024-08-31 22:39:06,824:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:06,824:INFO:Creating metrics dataframe
2024-08-31 22:39:06,828:INFO:Initializing Extra Trees Classifier
2024-08-31 22:39:06,829:INFO:Total runtime is 0.1324652314186096 minutes
2024-08-31 22:39:06,830:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:06,830:INFO:Initializing create_model()
2024-08-31 22:39:06,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:06,830:INFO:Checking exceptions
2024-08-31 22:39:06,830:INFO:Importing libraries
2024-08-31 22:39:06,830:INFO:Copying training dataset
2024-08-31 22:39:06,832:INFO:Defining folds
2024-08-31 22:39:06,832:INFO:Declaring metric variables
2024-08-31 22:39:06,833:INFO:Importing untrained model
2024-08-31 22:39:06,834:INFO:Extra Trees Classifier Imported successfully
2024-08-31 22:39:06,836:INFO:Starting cross validation
2024-08-31 22:39:06,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:07,295:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:07,297:INFO:Calculating mean and std
2024-08-31 22:39:07,297:INFO:Creating metrics dataframe
2024-08-31 22:39:07,299:INFO:Uploading results into container
2024-08-31 22:39:07,299:INFO:Uploading model into container now
2024-08-31 22:39:07,299:INFO:_master_model_container: 13
2024-08-31 22:39:07,299:INFO:_display_container: 2
2024-08-31 22:39:07,299:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-31 22:39:07,299:INFO:create_model() successfully completed......................................
2024-08-31 22:39:07,368:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:07,368:INFO:Creating metrics dataframe
2024-08-31 22:39:07,372:INFO:Initializing Extreme Gradient Boosting
2024-08-31 22:39:07,372:INFO:Total runtime is 0.14152564605077106 minutes
2024-08-31 22:39:07,373:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:07,373:INFO:Initializing create_model()
2024-08-31 22:39:07,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:07,374:INFO:Checking exceptions
2024-08-31 22:39:07,374:INFO:Importing libraries
2024-08-31 22:39:07,374:INFO:Copying training dataset
2024-08-31 22:39:07,375:INFO:Defining folds
2024-08-31 22:39:07,375:INFO:Declaring metric variables
2024-08-31 22:39:07,376:INFO:Importing untrained model
2024-08-31 22:39:07,377:INFO:Extreme Gradient Boosting Imported successfully
2024-08-31 22:39:07,379:INFO:Starting cross validation
2024-08-31 22:39:07,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:07,779:INFO:Calculating mean and std
2024-08-31 22:39:07,780:INFO:Creating metrics dataframe
2024-08-31 22:39:07,781:INFO:Uploading results into container
2024-08-31 22:39:07,781:INFO:Uploading model into container now
2024-08-31 22:39:07,782:INFO:_master_model_container: 14
2024-08-31 22:39:07,782:INFO:_display_container: 2
2024-08-31 22:39:07,782:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-08-31 22:39:07,782:INFO:create_model() successfully completed......................................
2024-08-31 22:39:07,851:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:07,851:INFO:Creating metrics dataframe
2024-08-31 22:39:07,856:INFO:Initializing Light Gradient Boosting Machine
2024-08-31 22:39:07,856:INFO:Total runtime is 0.14958266814549762 minutes
2024-08-31 22:39:07,857:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:07,857:INFO:Initializing create_model()
2024-08-31 22:39:07,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:07,857:INFO:Checking exceptions
2024-08-31 22:39:07,857:INFO:Importing libraries
2024-08-31 22:39:07,857:INFO:Copying training dataset
2024-08-31 22:39:07,858:INFO:Defining folds
2024-08-31 22:39:07,858:INFO:Declaring metric variables
2024-08-31 22:39:07,859:INFO:Importing untrained model
2024-08-31 22:39:07,860:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-31 22:39:07,862:INFO:Starting cross validation
2024-08-31 22:39:07,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:28,882:INFO:Calculating mean and std
2024-08-31 22:39:28,882:INFO:Creating metrics dataframe
2024-08-31 22:39:28,884:INFO:Uploading results into container
2024-08-31 22:39:28,884:INFO:Uploading model into container now
2024-08-31 22:39:28,885:INFO:_master_model_container: 15
2024-08-31 22:39:28,885:INFO:_display_container: 2
2024-08-31 22:39:28,885:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-31 22:39:28,885:INFO:create_model() successfully completed......................................
2024-08-31 22:39:28,960:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:28,960:INFO:Creating metrics dataframe
2024-08-31 22:39:28,965:INFO:Initializing CatBoost Classifier
2024-08-31 22:39:28,965:INFO:Total runtime is 0.5014056166013081 minutes
2024-08-31 22:39:28,966:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:28,966:INFO:Initializing create_model()
2024-08-31 22:39:28,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:28,966:INFO:Checking exceptions
2024-08-31 22:39:28,967:INFO:Importing libraries
2024-08-31 22:39:28,967:INFO:Copying training dataset
2024-08-31 22:39:28,968:INFO:Defining folds
2024-08-31 22:39:28,968:INFO:Declaring metric variables
2024-08-31 22:39:28,969:INFO:Importing untrained model
2024-08-31 22:39:28,970:INFO:CatBoost Classifier Imported successfully
2024-08-31 22:39:28,972:INFO:Starting cross validation
2024-08-31 22:39:28,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:34,432:INFO:Calculating mean and std
2024-08-31 22:39:34,433:INFO:Creating metrics dataframe
2024-08-31 22:39:34,434:INFO:Uploading results into container
2024-08-31 22:39:34,434:INFO:Uploading model into container now
2024-08-31 22:39:34,435:INFO:_master_model_container: 16
2024-08-31 22:39:34,435:INFO:_display_container: 2
2024-08-31 22:39:34,435:INFO:<catboost.core.CatBoostClassifier object at 0x288740d50>
2024-08-31 22:39:34,435:INFO:create_model() successfully completed......................................
2024-08-31 22:39:34,503:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:34,503:INFO:Creating metrics dataframe
2024-08-31 22:39:34,508:INFO:Initializing Dummy Classifier
2024-08-31 22:39:34,508:INFO:Total runtime is 0.5937840342521666 minutes
2024-08-31 22:39:34,509:INFO:SubProcess create_model() called ==================================
2024-08-31 22:39:34,509:INFO:Initializing create_model()
2024-08-31 22:39:34,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2887fc290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:34,509:INFO:Checking exceptions
2024-08-31 22:39:34,509:INFO:Importing libraries
2024-08-31 22:39:34,509:INFO:Copying training dataset
2024-08-31 22:39:34,510:INFO:Defining folds
2024-08-31 22:39:34,510:INFO:Declaring metric variables
2024-08-31 22:39:34,511:INFO:Importing untrained model
2024-08-31 22:39:34,512:INFO:Dummy Classifier Imported successfully
2024-08-31 22:39:34,514:INFO:Starting cross validation
2024-08-31 22:39:34,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:39:34,587:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,587:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,595:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,619:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,622:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,635:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,639:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,644:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,650:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,656:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:39:34,658:INFO:Calculating mean and std
2024-08-31 22:39:34,660:INFO:Creating metrics dataframe
2024-08-31 22:39:34,661:INFO:Uploading results into container
2024-08-31 22:39:34,662:INFO:Uploading model into container now
2024-08-31 22:39:34,662:INFO:_master_model_container: 17
2024-08-31 22:39:34,662:INFO:_display_container: 2
2024-08-31 22:39:34,662:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-08-31 22:39:34,662:INFO:create_model() successfully completed......................................
2024-08-31 22:39:34,736:INFO:SubProcess create_model() end ==================================
2024-08-31 22:39:34,737:INFO:Creating metrics dataframe
2024-08-31 22:39:34,744:INFO:Initializing create_model()
2024-08-31 22:39:34,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x284790790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:39:34,744:INFO:Checking exceptions
2024-08-31 22:39:34,745:INFO:Importing libraries
2024-08-31 22:39:34,745:INFO:Copying training dataset
2024-08-31 22:39:34,747:INFO:Defining folds
2024-08-31 22:39:34,747:INFO:Declaring metric variables
2024-08-31 22:39:34,747:INFO:Importing untrained model
2024-08-31 22:39:34,747:INFO:Declaring custom model
2024-08-31 22:39:34,747:INFO:Gradient Boosting Classifier Imported successfully
2024-08-31 22:39:34,747:INFO:Cross validation set to False
2024-08-31 22:39:34,747:INFO:Fitting Model
2024-08-31 22:39:35,603:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-31 22:39:35,603:INFO:create_model() successfully completed......................................
2024-08-31 22:39:35,678:INFO:_master_model_container: 17
2024-08-31 22:39:35,678:INFO:_display_container: 2
2024-08-31 22:39:35,678:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-31 22:39:35,678:INFO:compare_models() successfully completed......................................
2024-08-31 22:40:03,034:INFO:Initializing save_model()
2024-08-31 22:40:03,035:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-31 22:40:03,035:INFO:Adding model into prep_pipe
2024-08-31 22:40:03,047:INFO:student_performance_model.pkl saved in current working directory
2024-08-31 22:40:03,074:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Gender...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-08-31 22:40:03,074:INFO:save_model() successfully completed......................................
2024-08-31 22:42:42,556:INFO:PyCaret ClassificationExperiment
2024-08-31 22:42:42,556:INFO:Logging name: clf-default-name
2024-08-31 22:42:42,556:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-31 22:42:42,556:INFO:version 3.3.2
2024-08-31 22:42:42,556:INFO:Initializing setup()
2024-08-31 22:42:42,556:INFO:self.USI: 303c
2024-08-31 22:42:42,557:INFO:self._variable_keys: {'memory', 'gpu_param', 'log_plots_param', 'fold_generator', 'logging_param', 'target_param', 'y', 'fix_imbalance', 'exp_name_log', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'data', 'X_train', 'is_multiclass', 'exp_id', 'y_train', 'fold_shuffle_param', 'fold_groups_param', 'y_test', '_ml_usecase', 'idx', 'seed', 'USI', 'html_param', '_available_plots', 'X', 'X_test'}
2024-08-31 22:42:42,557:INFO:Checking environment
2024-08-31 22:42:42,557:INFO:python_version: 3.11.5
2024-08-31 22:42:42,557:INFO:python_build: ('main', 'Sep 11 2023 08:17:37')
2024-08-31 22:42:42,557:INFO:machine: arm64
2024-08-31 22:42:42,557:INFO:platform: macOS-13.2.1-arm64-arm-64bit
2024-08-31 22:42:42,557:INFO:Memory: svmem(total=8589934592, available=1864318976, percent=78.3, used=3033677824, free=60162048, active=1817411584, inactive=1802698752, wired=1216266240)
2024-08-31 22:42:42,557:INFO:Physical Core: 8
2024-08-31 22:42:42,557:INFO:Logical Core: 8
2024-08-31 22:42:42,557:INFO:Checking libraries
2024-08-31 22:42:42,557:INFO:System:
2024-08-31 22:42:42,558:INFO:    python: 3.11.5 (main, Sep 11 2023, 08:17:37) [Clang 14.0.6 ]
2024-08-31 22:42:42,558:INFO:executable: /Users/fady/anaconda3/bin/python
2024-08-31 22:42:42,558:INFO:   machine: macOS-13.2.1-arm64-arm-64bit
2024-08-31 22:42:42,558:INFO:PyCaret required dependencies:
2024-08-31 22:42:42,558:INFO:                 pip: 23.2.1
2024-08-31 22:42:42,558:INFO:          setuptools: 68.0.0
2024-08-31 22:42:42,558:INFO:             pycaret: 3.3.2
2024-08-31 22:42:42,558:INFO:             IPython: 8.20.0
2024-08-31 22:42:42,558:INFO:          ipywidgets: 8.1.2
2024-08-31 22:42:42,558:INFO:                tqdm: 4.65.0
2024-08-31 22:42:42,558:INFO:               numpy: 1.26.4
2024-08-31 22:42:42,558:INFO:              pandas: 1.5.3
2024-08-31 22:42:42,558:INFO:              jinja2: 3.0.3
2024-08-31 22:42:42,558:INFO:               scipy: 1.10.0
2024-08-31 22:42:42,558:INFO:              joblib: 1.2.0
2024-08-31 22:42:42,558:INFO:             sklearn: 1.4.2
2024-08-31 22:42:42,558:INFO:                pyod: 2.0.1
2024-08-31 22:42:42,558:INFO:            imblearn: 0.12.3
2024-08-31 22:42:42,558:INFO:   category_encoders: 2.6.3
2024-08-31 22:42:42,558:INFO:            lightgbm: 4.5.0
2024-08-31 22:42:42,558:INFO:               numba: 0.59.0
2024-08-31 22:42:42,558:INFO:            requests: 2.31.0
2024-08-31 22:42:42,558:INFO:          matplotlib: 3.7.5
2024-08-31 22:42:42,558:INFO:          scikitplot: 0.3.7
2024-08-31 22:42:42,558:INFO:         yellowbrick: 1.5
2024-08-31 22:42:42,558:INFO:              plotly: 5.19.0
2024-08-31 22:42:42,558:INFO:    plotly-resampler: Not installed
2024-08-31 22:42:42,558:INFO:             kaleido: 0.2.1
2024-08-31 22:42:42,558:INFO:           schemdraw: 0.15
2024-08-31 22:42:42,559:INFO:         statsmodels: 0.14.0
2024-08-31 22:42:42,559:INFO:              sktime: 0.26.0
2024-08-31 22:42:42,559:INFO:               tbats: 1.1.3
2024-08-31 22:42:42,559:INFO:            pmdarima: 2.0.4
2024-08-31 22:42:42,559:INFO:              psutil: 5.9.0
2024-08-31 22:42:42,559:INFO:          markupsafe: 2.1.3
2024-08-31 22:42:42,559:INFO:             pickle5: Not installed
2024-08-31 22:42:42,559:INFO:         cloudpickle: 2.2.1
2024-08-31 22:42:42,559:INFO:         deprecation: 2.1.0
2024-08-31 22:42:42,559:INFO:              xxhash: 2.0.2
2024-08-31 22:42:42,559:INFO:           wurlitzer: 3.0.2
2024-08-31 22:42:42,559:INFO:PyCaret optional dependencies:
2024-08-31 22:42:42,559:INFO:                shap: Not installed
2024-08-31 22:42:42,559:INFO:           interpret: Not installed
2024-08-31 22:42:42,559:INFO:                umap: Not installed
2024-08-31 22:42:42,559:INFO:     ydata_profiling: Not installed
2024-08-31 22:42:42,559:INFO:  explainerdashboard: Not installed
2024-08-31 22:42:42,559:INFO:             autoviz: Not installed
2024-08-31 22:42:42,559:INFO:           fairlearn: Not installed
2024-08-31 22:42:42,559:INFO:          deepchecks: Not installed
2024-08-31 22:42:42,559:INFO:             xgboost: 2.0.3
2024-08-31 22:42:42,559:INFO:            catboost: 1.2
2024-08-31 22:42:42,559:INFO:              kmodes: Not installed
2024-08-31 22:42:42,559:INFO:             mlxtend: Not installed
2024-08-31 22:42:42,559:INFO:       statsforecast: Not installed
2024-08-31 22:42:42,559:INFO:        tune_sklearn: Not installed
2024-08-31 22:42:42,559:INFO:                 ray: Not installed
2024-08-31 22:42:42,559:INFO:            hyperopt: Not installed
2024-08-31 22:42:42,559:INFO:              optuna: Not installed
2024-08-31 22:42:42,559:INFO:               skopt: Not installed
2024-08-31 22:42:42,559:INFO:              mlflow: Not installed
2024-08-31 22:42:42,559:INFO:              gradio: Not installed
2024-08-31 22:42:42,559:INFO:             fastapi: Not installed
2024-08-31 22:42:42,559:INFO:             uvicorn: Not installed
2024-08-31 22:42:42,559:INFO:              m2cgen: Not installed
2024-08-31 22:42:42,559:INFO:           evidently: Not installed
2024-08-31 22:42:42,559:INFO:               fugue: Not installed
2024-08-31 22:42:42,559:INFO:           streamlit: Not installed
2024-08-31 22:42:42,559:INFO:             prophet: Not installed
2024-08-31 22:42:42,559:INFO:None
2024-08-31 22:42:42,559:INFO:Set up data.
2024-08-31 22:42:42,568:INFO:Set up folding strategy.
2024-08-31 22:42:42,568:INFO:Set up train/test split.
2024-08-31 22:42:42,572:INFO:Set up index.
2024-08-31 22:42:42,572:INFO:Assigning column types.
2024-08-31 22:42:42,574:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-31 22:42:42,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 22:42:42,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:42:42,621:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,623:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 22:42:42,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:42:42,652:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,653:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,654:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-31 22:42:42,670:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:42:42,680:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,681:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 22:42:42,708:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,709:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,709:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-31 22:42:42,736:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,737:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,764:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,764:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,765:INFO:Preparing preprocessing pipeline...
2024-08-31 22:42:42,765:INFO:Set up simple imputation.
2024-08-31 22:42:42,766:INFO:Set up encoding of ordinal features.
2024-08-31 22:42:42,768:INFO:Set up encoding of categorical features.
2024-08-31 22:42:42,801:INFO:Finished creating preprocessing pipeline.
2024-08-31 22:42:42,826:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-31 22:42:42,827:INFO:Creating final display dataframe.
2024-08-31 22:42:42,903:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        GradeClass
2                   Target type        Multiclass
3           Original data shape        (2392, 15)
4        Transformed data shape        (2392, 24)
5   Transformed train set shape        (1674, 24)
6    Transformed test set shape         (718, 24)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 9
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              303c
2024-08-31 22:42:42,933:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,934:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,961:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 22:42:42,962:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 22:42:42,962:INFO:setup() successfully completed in 0.41s...............
2024-08-31 22:42:46,939:INFO:Initializing compare_models()
2024-08-31 22:42:46,939:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-31 22:42:46,939:INFO:Checking exceptions
2024-08-31 22:42:46,944:INFO:Preparing display monitor
2024-08-31 22:42:46,962:INFO:Initializing Logistic Regression
2024-08-31 22:42:46,962:INFO:Total runtime is 2.8967857360839845e-06 minutes
2024-08-31 22:42:46,964:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:46,964:INFO:Initializing create_model()
2024-08-31 22:42:46,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:46,964:INFO:Checking exceptions
2024-08-31 22:42:46,964:INFO:Importing libraries
2024-08-31 22:42:46,964:INFO:Copying training dataset
2024-08-31 22:42:46,966:INFO:Defining folds
2024-08-31 22:42:46,966:INFO:Declaring metric variables
2024-08-31 22:42:46,968:INFO:Importing untrained model
2024-08-31 22:42:46,969:INFO:Logistic Regression Imported successfully
2024-08-31 22:42:46,971:INFO:Starting cross validation
2024-08-31 22:42:46,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:47,285:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,295:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,317:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,331:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:42:47,344:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,366:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,366:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:42:47,368:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 22:42:47,383:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,386:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,389:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,489:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,512:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:47,516:INFO:Calculating mean and std
2024-08-31 22:42:47,516:INFO:Creating metrics dataframe
2024-08-31 22:42:47,518:INFO:Uploading results into container
2024-08-31 22:42:47,518:INFO:Uploading model into container now
2024-08-31 22:42:47,518:INFO:_master_model_container: 1
2024-08-31 22:42:47,518:INFO:_display_container: 2
2024-08-31 22:42:47,518:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 22:42:47,518:INFO:create_model() successfully completed......................................
2024-08-31 22:42:47,621:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:47,621:INFO:Creating metrics dataframe
2024-08-31 22:42:47,624:INFO:Initializing K Neighbors Classifier
2024-08-31 22:42:47,624:INFO:Total runtime is 0.011030582586924235 minutes
2024-08-31 22:42:47,625:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:47,625:INFO:Initializing create_model()
2024-08-31 22:42:47,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:47,625:INFO:Checking exceptions
2024-08-31 22:42:47,625:INFO:Importing libraries
2024-08-31 22:42:47,625:INFO:Copying training dataset
2024-08-31 22:42:47,627:INFO:Defining folds
2024-08-31 22:42:47,627:INFO:Declaring metric variables
2024-08-31 22:42:47,628:INFO:Importing untrained model
2024-08-31 22:42:47,629:INFO:K Neighbors Classifier Imported successfully
2024-08-31 22:42:47,631:INFO:Starting cross validation
2024-08-31 22:42:47,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:47,695:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,700:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,719:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,724:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,727:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,729:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,729:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,730:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,735:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,738:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,739:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,744:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,751:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,756:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,759:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,762:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,767:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,771:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,780:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,784:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,786:INFO:Calculating mean and std
2024-08-31 22:42:47,786:INFO:Creating metrics dataframe
2024-08-31 22:42:47,787:INFO:Uploading results into container
2024-08-31 22:42:47,787:INFO:Uploading model into container now
2024-08-31 22:42:47,787:INFO:_master_model_container: 2
2024-08-31 22:42:47,787:INFO:_display_container: 2
2024-08-31 22:42:47,787:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 22:42:47,787:INFO:create_model() successfully completed......................................
2024-08-31 22:42:47,855:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-31 22:42:47,856:WARNING:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-08-31 22:42:47,856:INFO:Initializing create_model()
2024-08-31 22:42:47,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:47,856:INFO:Checking exceptions
2024-08-31 22:42:47,856:INFO:Importing libraries
2024-08-31 22:42:47,856:INFO:Copying training dataset
2024-08-31 22:42:47,857:INFO:Defining folds
2024-08-31 22:42:47,857:INFO:Declaring metric variables
2024-08-31 22:42:47,858:INFO:Importing untrained model
2024-08-31 22:42:47,859:INFO:K Neighbors Classifier Imported successfully
2024-08-31 22:42:47,861:INFO:Starting cross validation
2024-08-31 22:42:47,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:47,938:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,941:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,949:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,950:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,951:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,955:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,957:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,959:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,959:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,966:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,971:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,971:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,976:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,977:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,979:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,982:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:47,998:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:48,002:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:48,003:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:48,007:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 22:42:48,008:INFO:Calculating mean and std
2024-08-31 22:42:48,008:INFO:Creating metrics dataframe
2024-08-31 22:42:48,010:INFO:Uploading results into container
2024-08-31 22:42:48,010:INFO:Uploading model into container now
2024-08-31 22:42:48,010:INFO:_master_model_container: 3
2024-08-31 22:42:48,010:INFO:_display_container: 2
2024-08-31 22:42:48,010:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 22:42:48,010:INFO:create_model() successfully completed......................................
2024-08-31 22:42:48,079:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2024-08-31 22:42:48,079:ERROR:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-08-31 22:42:48,079:INFO:Initializing Naive Bayes
2024-08-31 22:42:48,079:INFO:Total runtime is 0.01862026850382487 minutes
2024-08-31 22:42:48,080:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:48,081:INFO:Initializing create_model()
2024-08-31 22:42:48,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:48,081:INFO:Checking exceptions
2024-08-31 22:42:48,081:INFO:Importing libraries
2024-08-31 22:42:48,081:INFO:Copying training dataset
2024-08-31 22:42:48,082:INFO:Defining folds
2024-08-31 22:42:48,082:INFO:Declaring metric variables
2024-08-31 22:42:48,083:INFO:Importing untrained model
2024-08-31 22:42:48,084:INFO:Naive Bayes Imported successfully
2024-08-31 22:42:48,086:INFO:Starting cross validation
2024-08-31 22:42:48,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:48,167:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,173:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,173:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,177:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,190:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,193:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,194:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,210:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,221:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,227:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,229:INFO:Calculating mean and std
2024-08-31 22:42:48,230:INFO:Creating metrics dataframe
2024-08-31 22:42:48,231:INFO:Uploading results into container
2024-08-31 22:42:48,231:INFO:Uploading model into container now
2024-08-31 22:42:48,231:INFO:_master_model_container: 4
2024-08-31 22:42:48,231:INFO:_display_container: 2
2024-08-31 22:42:48,232:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-31 22:42:48,232:INFO:create_model() successfully completed......................................
2024-08-31 22:42:48,302:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:48,302:INFO:Creating metrics dataframe
2024-08-31 22:42:48,306:INFO:Initializing Decision Tree Classifier
2024-08-31 22:42:48,306:INFO:Total runtime is 0.02239286502202352 minutes
2024-08-31 22:42:48,307:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:48,307:INFO:Initializing create_model()
2024-08-31 22:42:48,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:48,307:INFO:Checking exceptions
2024-08-31 22:42:48,307:INFO:Importing libraries
2024-08-31 22:42:48,307:INFO:Copying training dataset
2024-08-31 22:42:48,309:INFO:Defining folds
2024-08-31 22:42:48,309:INFO:Declaring metric variables
2024-08-31 22:42:48,310:INFO:Importing untrained model
2024-08-31 22:42:48,311:INFO:Decision Tree Classifier Imported successfully
2024-08-31 22:42:48,313:INFO:Starting cross validation
2024-08-31 22:42:48,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:48,470:INFO:Calculating mean and std
2024-08-31 22:42:48,471:INFO:Creating metrics dataframe
2024-08-31 22:42:48,472:INFO:Uploading results into container
2024-08-31 22:42:48,472:INFO:Uploading model into container now
2024-08-31 22:42:48,472:INFO:_master_model_container: 5
2024-08-31 22:42:48,472:INFO:_display_container: 2
2024-08-31 22:42:48,472:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-31 22:42:48,473:INFO:create_model() successfully completed......................................
2024-08-31 22:42:48,539:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:48,540:INFO:Creating metrics dataframe
2024-08-31 22:42:48,543:INFO:Initializing SVM - Linear Kernel
2024-08-31 22:42:48,543:INFO:Total runtime is 0.026349914073944092 minutes
2024-08-31 22:42:48,544:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:48,544:INFO:Initializing create_model()
2024-08-31 22:42:48,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:48,544:INFO:Checking exceptions
2024-08-31 22:42:48,544:INFO:Importing libraries
2024-08-31 22:42:48,544:INFO:Copying training dataset
2024-08-31 22:42:48,546:INFO:Defining folds
2024-08-31 22:42:48,546:INFO:Declaring metric variables
2024-08-31 22:42:48,547:INFO:Importing untrained model
2024-08-31 22:42:48,548:INFO:SVM - Linear Kernel Imported successfully
2024-08-31 22:42:48,550:INFO:Starting cross validation
2024-08-31 22:42:48,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:48,654:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,673:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,686:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,687:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,687:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,691:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,692:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,693:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,699:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,706:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,706:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,708:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,709:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,709:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,745:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,746:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,746:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,747:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,749:INFO:Calculating mean and std
2024-08-31 22:42:48,750:INFO:Creating metrics dataframe
2024-08-31 22:42:48,751:INFO:Uploading results into container
2024-08-31 22:42:48,751:INFO:Uploading model into container now
2024-08-31 22:42:48,751:INFO:_master_model_container: 6
2024-08-31 22:42:48,751:INFO:_display_container: 2
2024-08-31 22:42:48,751:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-31 22:42:48,751:INFO:create_model() successfully completed......................................
2024-08-31 22:42:48,817:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:48,817:INFO:Creating metrics dataframe
2024-08-31 22:42:48,821:INFO:Initializing Ridge Classifier
2024-08-31 22:42:48,821:INFO:Total runtime is 0.030982247988382977 minutes
2024-08-31 22:42:48,822:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:48,822:INFO:Initializing create_model()
2024-08-31 22:42:48,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:48,823:INFO:Checking exceptions
2024-08-31 22:42:48,823:INFO:Importing libraries
2024-08-31 22:42:48,823:INFO:Copying training dataset
2024-08-31 22:42:48,824:INFO:Defining folds
2024-08-31 22:42:48,824:INFO:Declaring metric variables
2024-08-31 22:42:48,825:INFO:Importing untrained model
2024-08-31 22:42:48,826:INFO:Ridge Classifier Imported successfully
2024-08-31 22:42:48,828:INFO:Starting cross validation
2024-08-31 22:42:48,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:48,894:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,899:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,906:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,909:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,910:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,912:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,918:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,920:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,922:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,925:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,927:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,928:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,930:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,931:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,936:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,937:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,963:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,964:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,965:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:48,966:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:48,968:INFO:Calculating mean and std
2024-08-31 22:42:48,969:INFO:Creating metrics dataframe
2024-08-31 22:42:48,970:INFO:Uploading results into container
2024-08-31 22:42:48,970:INFO:Uploading model into container now
2024-08-31 22:42:48,970:INFO:_master_model_container: 7
2024-08-31 22:42:48,970:INFO:_display_container: 2
2024-08-31 22:42:48,970:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-31 22:42:48,971:INFO:create_model() successfully completed......................................
2024-08-31 22:42:49,038:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:49,039:INFO:Creating metrics dataframe
2024-08-31 22:42:49,042:INFO:Initializing Random Forest Classifier
2024-08-31 22:42:49,042:INFO:Total runtime is 0.03466800053914388 minutes
2024-08-31 22:42:49,043:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:49,043:INFO:Initializing create_model()
2024-08-31 22:42:49,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:49,044:INFO:Checking exceptions
2024-08-31 22:42:49,044:INFO:Importing libraries
2024-08-31 22:42:49,044:INFO:Copying training dataset
2024-08-31 22:42:49,045:INFO:Defining folds
2024-08-31 22:42:49,045:INFO:Declaring metric variables
2024-08-31 22:42:49,046:INFO:Importing untrained model
2024-08-31 22:42:49,047:INFO:Random Forest Classifier Imported successfully
2024-08-31 22:42:49,049:INFO:Starting cross validation
2024-08-31 22:42:49,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:49,501:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:42:49,503:INFO:Calculating mean and std
2024-08-31 22:42:49,503:INFO:Creating metrics dataframe
2024-08-31 22:42:49,504:INFO:Uploading results into container
2024-08-31 22:42:49,505:INFO:Uploading model into container now
2024-08-31 22:42:49,505:INFO:_master_model_container: 8
2024-08-31 22:42:49,505:INFO:_display_container: 2
2024-08-31 22:42:49,505:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-31 22:42:49,505:INFO:create_model() successfully completed......................................
2024-08-31 22:42:49,570:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:49,570:INFO:Creating metrics dataframe
2024-08-31 22:42:49,574:INFO:Initializing Quadratic Discriminant Analysis
2024-08-31 22:42:49,574:INFO:Total runtime is 0.043536031246185304 minutes
2024-08-31 22:42:49,575:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:49,575:INFO:Initializing create_model()
2024-08-31 22:42:49,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:49,575:INFO:Checking exceptions
2024-08-31 22:42:49,575:INFO:Importing libraries
2024-08-31 22:42:49,576:INFO:Copying training dataset
2024-08-31 22:42:49,577:INFO:Defining folds
2024-08-31 22:42:49,577:INFO:Declaring metric variables
2024-08-31 22:42:49,578:INFO:Importing untrained model
2024-08-31 22:42:49,579:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-31 22:42:49,580:INFO:Starting cross validation
2024-08-31 22:42:49,581:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:49,628:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,632:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,637:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,650:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,653:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,658:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,660:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,663:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,663:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,667:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,669:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,669:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,681:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,681:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,682:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,688:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,704:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,709:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 22:42:49,717:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,721:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,724:INFO:Calculating mean and std
2024-08-31 22:42:49,725:INFO:Creating metrics dataframe
2024-08-31 22:42:49,726:INFO:Uploading results into container
2024-08-31 22:42:49,726:INFO:Uploading model into container now
2024-08-31 22:42:49,726:INFO:_master_model_container: 9
2024-08-31 22:42:49,726:INFO:_display_container: 2
2024-08-31 22:42:49,726:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-31 22:42:49,727:INFO:create_model() successfully completed......................................
2024-08-31 22:42:49,794:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:49,794:INFO:Creating metrics dataframe
2024-08-31 22:42:49,798:INFO:Initializing Ada Boost Classifier
2024-08-31 22:42:49,798:INFO:Total runtime is 0.047270949681599936 minutes
2024-08-31 22:42:49,799:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:49,800:INFO:Initializing create_model()
2024-08-31 22:42:49,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:49,800:INFO:Checking exceptions
2024-08-31 22:42:49,800:INFO:Importing libraries
2024-08-31 22:42:49,800:INFO:Copying training dataset
2024-08-31 22:42:49,801:INFO:Defining folds
2024-08-31 22:42:49,801:INFO:Declaring metric variables
2024-08-31 22:42:49,802:INFO:Importing untrained model
2024-08-31 22:42:49,803:INFO:Ada Boost Classifier Imported successfully
2024-08-31 22:42:49,805:INFO:Starting cross validation
2024-08-31 22:42:49,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:49,854:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,871:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,874:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,875:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,880:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,880:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,893:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,918:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:49,969:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,975:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,978:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,985:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,986:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,990:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:49,992:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:50,005:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:50,006:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:50,019:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 22:42:50,067:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:50,079:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:50,082:INFO:Calculating mean and std
2024-08-31 22:42:50,082:INFO:Creating metrics dataframe
2024-08-31 22:42:50,084:INFO:Uploading results into container
2024-08-31 22:42:50,084:INFO:Uploading model into container now
2024-08-31 22:42:50,084:INFO:_master_model_container: 10
2024-08-31 22:42:50,084:INFO:_display_container: 2
2024-08-31 22:42:50,084:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-08-31 22:42:50,084:INFO:create_model() successfully completed......................................
2024-08-31 22:42:50,150:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:50,150:INFO:Creating metrics dataframe
2024-08-31 22:42:50,154:INFO:Initializing Gradient Boosting Classifier
2024-08-31 22:42:50,154:INFO:Total runtime is 0.053201067447662356 minutes
2024-08-31 22:42:50,155:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:50,155:INFO:Initializing create_model()
2024-08-31 22:42:50,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:50,155:INFO:Checking exceptions
2024-08-31 22:42:50,155:INFO:Importing libraries
2024-08-31 22:42:50,155:INFO:Copying training dataset
2024-08-31 22:42:50,157:INFO:Defining folds
2024-08-31 22:42:50,157:INFO:Declaring metric variables
2024-08-31 22:42:50,158:INFO:Importing untrained model
2024-08-31 22:42:50,159:INFO:Gradient Boosting Classifier Imported successfully
2024-08-31 22:42:50,160:INFO:Starting cross validation
2024-08-31 22:42:50,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:51,035:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,069:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,070:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,088:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,090:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,094:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,106:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,112:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,711:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,731:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,734:INFO:Calculating mean and std
2024-08-31 22:42:51,734:INFO:Creating metrics dataframe
2024-08-31 22:42:51,735:INFO:Uploading results into container
2024-08-31 22:42:51,736:INFO:Uploading model into container now
2024-08-31 22:42:51,736:INFO:_master_model_container: 11
2024-08-31 22:42:51,736:INFO:_display_container: 2
2024-08-31 22:42:51,736:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-31 22:42:51,736:INFO:create_model() successfully completed......................................
2024-08-31 22:42:51,801:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:51,801:INFO:Creating metrics dataframe
2024-08-31 22:42:51,805:INFO:Initializing Linear Discriminant Analysis
2024-08-31 22:42:51,805:INFO:Total runtime is 0.08072219689687093 minutes
2024-08-31 22:42:51,806:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:51,806:INFO:Initializing create_model()
2024-08-31 22:42:51,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:51,807:INFO:Checking exceptions
2024-08-31 22:42:51,807:INFO:Importing libraries
2024-08-31 22:42:51,807:INFO:Copying training dataset
2024-08-31 22:42:51,808:INFO:Defining folds
2024-08-31 22:42:51,808:INFO:Declaring metric variables
2024-08-31 22:42:51,809:INFO:Importing untrained model
2024-08-31 22:42:51,810:INFO:Linear Discriminant Analysis Imported successfully
2024-08-31 22:42:51,812:INFO:Starting cross validation
2024-08-31 22:42:51,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:51,890:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,891:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,899:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,904:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,908:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,908:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,917:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,921:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,950:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,958:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 22:42:51,961:INFO:Calculating mean and std
2024-08-31 22:42:51,961:INFO:Creating metrics dataframe
2024-08-31 22:42:51,962:INFO:Uploading results into container
2024-08-31 22:42:51,963:INFO:Uploading model into container now
2024-08-31 22:42:51,963:INFO:_master_model_container: 12
2024-08-31 22:42:51,963:INFO:_display_container: 2
2024-08-31 22:42:51,963:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-31 22:42:51,963:INFO:create_model() successfully completed......................................
2024-08-31 22:42:52,029:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:52,029:INFO:Creating metrics dataframe
2024-08-31 22:42:52,034:INFO:Initializing Extra Trees Classifier
2024-08-31 22:42:52,034:INFO:Total runtime is 0.0845306674639384 minutes
2024-08-31 22:42:52,035:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:52,035:INFO:Initializing create_model()
2024-08-31 22:42:52,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:52,035:INFO:Checking exceptions
2024-08-31 22:42:52,035:INFO:Importing libraries
2024-08-31 22:42:52,035:INFO:Copying training dataset
2024-08-31 22:42:52,037:INFO:Defining folds
2024-08-31 22:42:52,037:INFO:Declaring metric variables
2024-08-31 22:42:52,038:INFO:Importing untrained model
2024-08-31 22:42:52,039:INFO:Extra Trees Classifier Imported successfully
2024-08-31 22:42:52,041:INFO:Starting cross validation
2024-08-31 22:42:52,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:52,472:INFO:Calculating mean and std
2024-08-31 22:42:52,472:INFO:Creating metrics dataframe
2024-08-31 22:42:52,473:INFO:Uploading results into container
2024-08-31 22:42:52,474:INFO:Uploading model into container now
2024-08-31 22:42:52,474:INFO:_master_model_container: 13
2024-08-31 22:42:52,474:INFO:_display_container: 2
2024-08-31 22:42:52,474:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-31 22:42:52,474:INFO:create_model() successfully completed......................................
2024-08-31 22:42:52,539:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:52,540:INFO:Creating metrics dataframe
2024-08-31 22:42:52,543:INFO:Initializing Extreme Gradient Boosting
2024-08-31 22:42:52,543:INFO:Total runtime is 0.09302409887313844 minutes
2024-08-31 22:42:52,545:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:52,545:INFO:Initializing create_model()
2024-08-31 22:42:52,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:52,545:INFO:Checking exceptions
2024-08-31 22:42:52,545:INFO:Importing libraries
2024-08-31 22:42:52,545:INFO:Copying training dataset
2024-08-31 22:42:52,546:INFO:Defining folds
2024-08-31 22:42:52,546:INFO:Declaring metric variables
2024-08-31 22:42:52,547:INFO:Importing untrained model
2024-08-31 22:42:52,548:INFO:Extreme Gradient Boosting Imported successfully
2024-08-31 22:42:52,550:INFO:Starting cross validation
2024-08-31 22:42:52,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:42:52,945:INFO:Calculating mean and std
2024-08-31 22:42:52,946:INFO:Creating metrics dataframe
2024-08-31 22:42:52,947:INFO:Uploading results into container
2024-08-31 22:42:52,947:INFO:Uploading model into container now
2024-08-31 22:42:52,947:INFO:_master_model_container: 14
2024-08-31 22:42:52,947:INFO:_display_container: 2
2024-08-31 22:42:52,948:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-08-31 22:42:52,948:INFO:create_model() successfully completed......................................
2024-08-31 22:42:53,016:INFO:SubProcess create_model() end ==================================
2024-08-31 22:42:53,017:INFO:Creating metrics dataframe
2024-08-31 22:42:53,021:INFO:Initializing Light Gradient Boosting Machine
2024-08-31 22:42:53,021:INFO:Total runtime is 0.10097672939300538 minutes
2024-08-31 22:42:53,022:INFO:SubProcess create_model() called ==================================
2024-08-31 22:42:53,022:INFO:Initializing create_model()
2024-08-31 22:42:53,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:42:53,022:INFO:Checking exceptions
2024-08-31 22:42:53,022:INFO:Importing libraries
2024-08-31 22:42:53,022:INFO:Copying training dataset
2024-08-31 22:42:53,023:INFO:Defining folds
2024-08-31 22:42:53,023:INFO:Declaring metric variables
2024-08-31 22:42:53,024:INFO:Importing untrained model
2024-08-31 22:42:53,025:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-31 22:42:53,027:INFO:Starting cross validation
2024-08-31 22:42:53,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:43:15,390:INFO:Calculating mean and std
2024-08-31 22:43:15,392:INFO:Creating metrics dataframe
2024-08-31 22:43:15,395:INFO:Uploading results into container
2024-08-31 22:43:15,395:INFO:Uploading model into container now
2024-08-31 22:43:15,395:INFO:_master_model_container: 15
2024-08-31 22:43:15,395:INFO:_display_container: 2
2024-08-31 22:43:15,396:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-31 22:43:15,396:INFO:create_model() successfully completed......................................
2024-08-31 22:43:15,487:INFO:SubProcess create_model() end ==================================
2024-08-31 22:43:15,487:INFO:Creating metrics dataframe
2024-08-31 22:43:15,491:INFO:Initializing CatBoost Classifier
2024-08-31 22:43:15,491:INFO:Total runtime is 0.47549071311950686 minutes
2024-08-31 22:43:15,493:INFO:SubProcess create_model() called ==================================
2024-08-31 22:43:15,493:INFO:Initializing create_model()
2024-08-31 22:43:15,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:43:15,493:INFO:Checking exceptions
2024-08-31 22:43:15,493:INFO:Importing libraries
2024-08-31 22:43:15,493:INFO:Copying training dataset
2024-08-31 22:43:15,495:INFO:Defining folds
2024-08-31 22:43:15,495:INFO:Declaring metric variables
2024-08-31 22:43:15,496:INFO:Importing untrained model
2024-08-31 22:43:15,497:INFO:CatBoost Classifier Imported successfully
2024-08-31 22:43:15,499:INFO:Starting cross validation
2024-08-31 22:43:15,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:43:19,753:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,756:INFO:Calculating mean and std
2024-08-31 22:43:19,757:INFO:Creating metrics dataframe
2024-08-31 22:43:19,758:INFO:Uploading results into container
2024-08-31 22:43:19,758:INFO:Uploading model into container now
2024-08-31 22:43:19,758:INFO:_master_model_container: 16
2024-08-31 22:43:19,758:INFO:_display_container: 2
2024-08-31 22:43:19,758:INFO:<catboost.core.CatBoostClassifier object at 0x2887e1710>
2024-08-31 22:43:19,758:INFO:create_model() successfully completed......................................
2024-08-31 22:43:19,834:INFO:SubProcess create_model() end ==================================
2024-08-31 22:43:19,834:INFO:Creating metrics dataframe
2024-08-31 22:43:19,839:INFO:Initializing Dummy Classifier
2024-08-31 22:43:19,839:INFO:Total runtime is 0.5479491790135702 minutes
2024-08-31 22:43:19,840:INFO:SubProcess create_model() called ==================================
2024-08-31 22:43:19,840:INFO:Initializing create_model()
2024-08-31 22:43:19,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288804a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:43:19,840:INFO:Checking exceptions
2024-08-31 22:43:19,840:INFO:Importing libraries
2024-08-31 22:43:19,840:INFO:Copying training dataset
2024-08-31 22:43:19,842:INFO:Defining folds
2024-08-31 22:43:19,842:INFO:Declaring metric variables
2024-08-31 22:43:19,843:INFO:Importing untrained model
2024-08-31 22:43:19,844:INFO:Dummy Classifier Imported successfully
2024-08-31 22:43:19,846:INFO:Starting cross validation
2024-08-31 22:43:19,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 22:43:19,936:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,939:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,943:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,962:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,964:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,970:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,979:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:19,987:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:20,006:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:20,008:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 22:43:20,010:INFO:Calculating mean and std
2024-08-31 22:43:20,012:INFO:Creating metrics dataframe
2024-08-31 22:43:20,014:INFO:Uploading results into container
2024-08-31 22:43:20,014:INFO:Uploading model into container now
2024-08-31 22:43:20,015:INFO:_master_model_container: 17
2024-08-31 22:43:20,015:INFO:_display_container: 2
2024-08-31 22:43:20,015:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-08-31 22:43:20,015:INFO:create_model() successfully completed......................................
2024-08-31 22:43:20,093:INFO:SubProcess create_model() end ==================================
2024-08-31 22:43:20,094:INFO:Creating metrics dataframe
2024-08-31 22:43:20,102:INFO:Initializing create_model()
2024-08-31 22:43:20,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x28843a950>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 22:43:20,102:INFO:Checking exceptions
2024-08-31 22:43:20,102:INFO:Importing libraries
2024-08-31 22:43:20,103:INFO:Copying training dataset
2024-08-31 22:43:20,104:INFO:Defining folds
2024-08-31 22:43:20,104:INFO:Declaring metric variables
2024-08-31 22:43:20,104:INFO:Importing untrained model
2024-08-31 22:43:20,104:INFO:Declaring custom model
2024-08-31 22:43:20,104:INFO:Logistic Regression Imported successfully
2024-08-31 22:43:20,105:INFO:Cross validation set to False
2024-08-31 22:43:20,105:INFO:Fitting Model
2024-08-31 22:43:20,296:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 22:43:20,296:INFO:create_model() successfully completed......................................
2024-08-31 22:43:20,391:INFO:_master_model_container: 17
2024-08-31 22:43:20,391:INFO:_display_container: 2
2024-08-31 22:43:20,391:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 22:43:20,391:INFO:compare_models() successfully completed......................................
2024-08-31 22:43:20,424:INFO:Initializing save_model()
2024-08-31 22:43:20,424:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-31 22:43:20,424:INFO:Adding model into prep_pipe
2024-08-31 22:43:20,428:INFO:student_performance_model.pkl saved in current working directory
2024-08-31 22:43:20,459:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Gender...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-08-31 22:43:20,459:INFO:save_model() successfully completed......................................
2024-08-31 23:16:22,743:ERROR:
'fastapi' is a soft dependency and not included in the pycaret installation. Please run: `pip install fastapi` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-08-31 23:17:01,839:ERROR:
'fastapi' is a soft dependency and not included in the pycaret installation. Please run: `pip install fastapi` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-08-31 23:17:18,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:17:18,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:17:18,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:17:18,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:17:23,545:INFO:PyCaret ClassificationExperiment
2024-08-31 23:17:23,545:INFO:Logging name: clf-default-name
2024-08-31 23:17:23,546:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-31 23:17:23,546:INFO:version 3.3.2
2024-08-31 23:17:23,546:INFO:Initializing setup()
2024-08-31 23:17:23,546:INFO:self.USI: 5127
2024-08-31 23:17:23,546:INFO:self._variable_keys: {'_available_plots', '_ml_usecase', 'y', 'fold_groups_param', 'html_param', 'gpu_param', 'fold_shuffle_param', 'USI', 'seed', 'pipeline', 'y_test', 'n_jobs_param', 'target_param', 'X', 'idx', 'gpu_n_jobs_param', 'exp_id', 'exp_name_log', 'memory', 'fold_generator', 'data', 'y_train', 'is_multiclass', 'logging_param', 'fix_imbalance', 'log_plots_param', 'X_test', 'X_train'}
2024-08-31 23:17:23,546:INFO:Checking environment
2024-08-31 23:17:23,546:INFO:python_version: 3.11.5
2024-08-31 23:17:23,546:INFO:python_build: ('main', 'Sep 11 2023 08:17:37')
2024-08-31 23:17:23,546:INFO:machine: arm64
2024-08-31 23:17:23,546:INFO:platform: macOS-13.2.1-arm64-arm-64bit
2024-08-31 23:17:23,546:INFO:Memory: svmem(total=8589934592, available=2676473856, percent=68.8, used=3750002688, free=159416320, active=2343747584, inactive=2402713600, wired=1406255104)
2024-08-31 23:17:23,546:INFO:Physical Core: 8
2024-08-31 23:17:23,546:INFO:Logical Core: 8
2024-08-31 23:17:23,546:INFO:Checking libraries
2024-08-31 23:17:23,546:INFO:System:
2024-08-31 23:17:23,546:INFO:    python: 3.11.5 (main, Sep 11 2023, 08:17:37) [Clang 14.0.6 ]
2024-08-31 23:17:23,546:INFO:executable: /Users/fady/anaconda3/bin/python
2024-08-31 23:17:23,546:INFO:   machine: macOS-13.2.1-arm64-arm-64bit
2024-08-31 23:17:23,546:INFO:PyCaret required dependencies:
2024-08-31 23:17:23,678:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:23,829:INFO:                 pip: 23.2.1
2024-08-31 23:17:23,829:INFO:          setuptools: 68.0.0
2024-08-31 23:17:23,829:INFO:             pycaret: 3.3.2
2024-08-31 23:17:23,829:INFO:             IPython: 8.20.0
2024-08-31 23:17:23,829:INFO:          ipywidgets: 8.1.2
2024-08-31 23:17:23,829:INFO:                tqdm: 4.65.0
2024-08-31 23:17:23,829:INFO:               numpy: 1.26.4
2024-08-31 23:17:23,829:INFO:              pandas: 1.5.3
2024-08-31 23:17:23,829:INFO:              jinja2: 3.0.3
2024-08-31 23:17:23,829:INFO:               scipy: 1.10.0
2024-08-31 23:17:23,829:INFO:              joblib: 1.2.0
2024-08-31 23:17:23,829:INFO:             sklearn: 1.4.2
2024-08-31 23:17:23,829:INFO:                pyod: 2.0.1
2024-08-31 23:17:23,829:INFO:            imblearn: 0.12.3
2024-08-31 23:17:23,829:INFO:   category_encoders: 2.6.3
2024-08-31 23:17:23,829:INFO:            lightgbm: 4.5.0
2024-08-31 23:17:23,829:INFO:               numba: 0.59.0
2024-08-31 23:17:23,829:INFO:            requests: 2.31.0
2024-08-31 23:17:23,829:INFO:          matplotlib: 3.7.5
2024-08-31 23:17:23,829:INFO:          scikitplot: 0.3.7
2024-08-31 23:17:23,829:INFO:         yellowbrick: 1.5
2024-08-31 23:17:23,829:INFO:              plotly: 5.19.0
2024-08-31 23:17:23,829:INFO:    plotly-resampler: Not installed
2024-08-31 23:17:23,829:INFO:             kaleido: 0.2.1
2024-08-31 23:17:23,829:INFO:           schemdraw: 0.15
2024-08-31 23:17:23,829:INFO:         statsmodels: 0.14.0
2024-08-31 23:17:23,829:INFO:              sktime: 0.26.0
2024-08-31 23:17:23,829:INFO:               tbats: 1.1.3
2024-08-31 23:17:23,829:INFO:            pmdarima: 2.0.4
2024-08-31 23:17:23,829:INFO:              psutil: 5.9.0
2024-08-31 23:17:23,829:INFO:          markupsafe: 2.1.3
2024-08-31 23:17:23,829:INFO:             pickle5: Not installed
2024-08-31 23:17:23,829:INFO:         cloudpickle: 2.2.1
2024-08-31 23:17:23,829:INFO:         deprecation: 2.1.0
2024-08-31 23:17:23,829:INFO:              xxhash: 2.0.2
2024-08-31 23:17:23,829:INFO:           wurlitzer: 3.0.2
2024-08-31 23:17:23,829:INFO:PyCaret optional dependencies:
2024-08-31 23:17:24,707:INFO:                shap: Not installed
2024-08-31 23:17:24,707:INFO:           interpret: Not installed
2024-08-31 23:17:24,707:INFO:                umap: Not installed
2024-08-31 23:17:24,707:INFO:     ydata_profiling: Not installed
2024-08-31 23:17:24,707:INFO:  explainerdashboard: Not installed
2024-08-31 23:17:24,708:INFO:             autoviz: Not installed
2024-08-31 23:17:24,708:INFO:           fairlearn: Not installed
2024-08-31 23:17:24,708:INFO:          deepchecks: Not installed
2024-08-31 23:17:24,708:INFO:             xgboost: 2.0.3
2024-08-31 23:17:24,708:INFO:            catboost: 1.2
2024-08-31 23:17:24,708:INFO:              kmodes: Not installed
2024-08-31 23:17:24,708:INFO:             mlxtend: Not installed
2024-08-31 23:17:24,708:INFO:       statsforecast: Not installed
2024-08-31 23:17:24,708:INFO:        tune_sklearn: Not installed
2024-08-31 23:17:24,708:INFO:                 ray: Not installed
2024-08-31 23:17:24,708:INFO:            hyperopt: Not installed
2024-08-31 23:17:24,708:INFO:              optuna: Not installed
2024-08-31 23:17:24,708:INFO:               skopt: Not installed
2024-08-31 23:17:24,708:INFO:              mlflow: Not installed
2024-08-31 23:17:24,708:INFO:              gradio: Not installed
2024-08-31 23:17:24,708:INFO:             fastapi: 0.112.2
2024-08-31 23:17:24,708:INFO:             uvicorn: Not installed
2024-08-31 23:17:24,708:INFO:              m2cgen: Not installed
2024-08-31 23:17:24,708:INFO:           evidently: Not installed
2024-08-31 23:17:24,708:INFO:               fugue: Not installed
2024-08-31 23:17:24,708:INFO:           streamlit: Not installed
2024-08-31 23:17:24,708:INFO:             prophet: Not installed
2024-08-31 23:17:24,708:INFO:None
2024-08-31 23:17:24,708:INFO:Set up data.
2024-08-31 23:17:24,719:INFO:Set up folding strategy.
2024-08-31 23:17:24,719:INFO:Set up train/test split.
2024-08-31 23:17:24,724:INFO:Set up index.
2024-08-31 23:17:24,724:INFO:Assigning column types.
2024-08-31 23:17:24,726:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-31 23:17:24,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 23:17:24,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:17:24,774:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:24,775:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:24,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 23:17:24,803:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:17:24,812:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:24,813:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:24,813:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-31 23:17:24,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:17:24,840:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:24,840:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:24,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:17:24,867:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:24,868:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:24,868:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-31 23:17:24,894:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:24,895:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:24,922:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:24,922:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:24,924:INFO:Preparing preprocessing pipeline...
2024-08-31 23:17:24,924:INFO:Set up simple imputation.
2024-08-31 23:17:24,925:INFO:Set up encoding of ordinal features.
2024-08-31 23:17:24,927:INFO:Set up encoding of categorical features.
2024-08-31 23:17:24,960:INFO:Finished creating preprocessing pipeline.
2024-08-31 23:17:24,986:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-31 23:17:24,986:INFO:Creating final display dataframe.
2024-08-31 23:17:25,061:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        GradeClass
2                   Target type        Multiclass
3           Original data shape        (2392, 15)
4        Transformed data shape        (2392, 24)
5   Transformed train set shape        (1674, 24)
6    Transformed test set shape         (718, 24)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 9
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5127
2024-08-31 23:17:25,090:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:25,091:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:25,118:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:17:25,119:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:17:25,120:INFO:setup() successfully completed in 1.58s...............
2024-08-31 23:17:33,441:INFO:Initializing compare_models()
2024-08-31 23:17:33,442:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-31 23:17:33,442:INFO:Checking exceptions
2024-08-31 23:17:33,448:INFO:Preparing display monitor
2024-08-31 23:17:33,480:INFO:Initializing Logistic Regression
2024-08-31 23:17:33,480:INFO:Total runtime is 4.037221272786458e-06 minutes
2024-08-31 23:17:33,481:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:33,481:INFO:Initializing create_model()
2024-08-31 23:17:33,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:33,482:INFO:Checking exceptions
2024-08-31 23:17:33,482:INFO:Importing libraries
2024-08-31 23:17:33,482:INFO:Copying training dataset
2024-08-31 23:17:33,484:INFO:Defining folds
2024-08-31 23:17:33,484:INFO:Declaring metric variables
2024-08-31 23:17:33,486:INFO:Importing untrained model
2024-08-31 23:17:33,487:INFO:Logistic Regression Imported successfully
2024-08-31 23:17:33,490:INFO:Starting cross validation
2024-08-31 23:17:33,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:35,227:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,426:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,426:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,430:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,442:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,455:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,455:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,472:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:17:35,771:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:35,989:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,018:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 23:17:36,020:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,024:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,031:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,036:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 23:17:36,044:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 23:17:36,058:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,065:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,066:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,083:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,256:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:36,260:INFO:Calculating mean and std
2024-08-31 23:17:36,261:INFO:Creating metrics dataframe
2024-08-31 23:17:36,264:INFO:Uploading results into container
2024-08-31 23:17:36,264:INFO:Uploading model into container now
2024-08-31 23:17:36,265:INFO:_master_model_container: 1
2024-08-31 23:17:36,265:INFO:_display_container: 2
2024-08-31 23:17:36,265:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 23:17:36,265:INFO:create_model() successfully completed......................................
2024-08-31 23:17:36,354:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:36,354:INFO:Creating metrics dataframe
2024-08-31 23:17:36,358:INFO:Initializing K Neighbors Classifier
2024-08-31 23:17:36,358:INFO:Total runtime is 0.047969416777292884 minutes
2024-08-31 23:17:36,359:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:36,359:INFO:Initializing create_model()
2024-08-31 23:17:36,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:36,359:INFO:Checking exceptions
2024-08-31 23:17:36,359:INFO:Importing libraries
2024-08-31 23:17:36,359:INFO:Copying training dataset
2024-08-31 23:17:36,361:INFO:Defining folds
2024-08-31 23:17:36,361:INFO:Declaring metric variables
2024-08-31 23:17:36,363:INFO:Importing untrained model
2024-08-31 23:17:36,365:INFO:K Neighbors Classifier Imported successfully
2024-08-31 23:17:36,367:INFO:Starting cross validation
2024-08-31 23:17:36,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:36,459:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,463:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,470:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,471:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,472:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,472:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,477:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,478:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,480:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,485:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,488:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,492:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,493:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,494:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,501:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,506:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,525:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,525:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,530:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,530:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,531:INFO:Calculating mean and std
2024-08-31 23:17:36,531:INFO:Creating metrics dataframe
2024-08-31 23:17:36,532:INFO:Uploading results into container
2024-08-31 23:17:36,533:INFO:Uploading model into container now
2024-08-31 23:17:36,533:INFO:_master_model_container: 2
2024-08-31 23:17:36,533:INFO:_display_container: 2
2024-08-31 23:17:36,533:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 23:17:36,533:INFO:create_model() successfully completed......................................
2024-08-31 23:17:36,587:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-31 23:17:36,590:WARNING:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-08-31 23:17:36,590:INFO:Initializing create_model()
2024-08-31 23:17:36,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:36,590:INFO:Checking exceptions
2024-08-31 23:17:36,590:INFO:Importing libraries
2024-08-31 23:17:36,590:INFO:Copying training dataset
2024-08-31 23:17:36,591:INFO:Defining folds
2024-08-31 23:17:36,591:INFO:Declaring metric variables
2024-08-31 23:17:36,592:INFO:Importing untrained model
2024-08-31 23:17:36,593:INFO:K Neighbors Classifier Imported successfully
2024-08-31 23:17:36,595:INFO:Starting cross validation
2024-08-31 23:17:36,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:36,658:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,659:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,664:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,666:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,667:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,672:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,693:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,697:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,702:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,702:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,703:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,704:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,706:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,706:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,708:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,711:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,727:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,729:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,731:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,734:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:17:36,734:INFO:Calculating mean and std
2024-08-31 23:17:36,735:INFO:Creating metrics dataframe
2024-08-31 23:17:36,736:INFO:Uploading results into container
2024-08-31 23:17:36,736:INFO:Uploading model into container now
2024-08-31 23:17:36,736:INFO:_master_model_container: 3
2024-08-31 23:17:36,736:INFO:_display_container: 2
2024-08-31 23:17:36,736:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 23:17:36,736:INFO:create_model() successfully completed......................................
2024-08-31 23:17:36,790:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2024-08-31 23:17:36,790:ERROR:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-08-31 23:17:36,790:INFO:Initializing Naive Bayes
2024-08-31 23:17:36,791:INFO:Total runtime is 0.05518381595611572 minutes
2024-08-31 23:17:36,792:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:36,792:INFO:Initializing create_model()
2024-08-31 23:17:36,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:36,792:INFO:Checking exceptions
2024-08-31 23:17:36,792:INFO:Importing libraries
2024-08-31 23:17:36,793:INFO:Copying training dataset
2024-08-31 23:17:36,794:INFO:Defining folds
2024-08-31 23:17:36,794:INFO:Declaring metric variables
2024-08-31 23:17:36,795:INFO:Importing untrained model
2024-08-31 23:17:36,796:INFO:Naive Bayes Imported successfully
2024-08-31 23:17:36,797:INFO:Starting cross validation
2024-08-31 23:17:36,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:36,868:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,883:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,893:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,893:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,903:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,906:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,908:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,910:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,933:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,943:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:36,945:INFO:Calculating mean and std
2024-08-31 23:17:36,946:INFO:Creating metrics dataframe
2024-08-31 23:17:36,947:INFO:Uploading results into container
2024-08-31 23:17:36,947:INFO:Uploading model into container now
2024-08-31 23:17:36,947:INFO:_master_model_container: 4
2024-08-31 23:17:36,947:INFO:_display_container: 2
2024-08-31 23:17:36,947:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-31 23:17:36,947:INFO:create_model() successfully completed......................................
2024-08-31 23:17:37,000:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:37,000:INFO:Creating metrics dataframe
2024-08-31 23:17:37,004:INFO:Initializing Decision Tree Classifier
2024-08-31 23:17:37,004:INFO:Total runtime is 0.058745284875233963 minutes
2024-08-31 23:17:37,005:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:37,006:INFO:Initializing create_model()
2024-08-31 23:17:37,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:37,006:INFO:Checking exceptions
2024-08-31 23:17:37,006:INFO:Importing libraries
2024-08-31 23:17:37,006:INFO:Copying training dataset
2024-08-31 23:17:37,007:INFO:Defining folds
2024-08-31 23:17:37,007:INFO:Declaring metric variables
2024-08-31 23:17:37,008:INFO:Importing untrained model
2024-08-31 23:17:37,009:INFO:Decision Tree Classifier Imported successfully
2024-08-31 23:17:37,011:INFO:Starting cross validation
2024-08-31 23:17:37,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:37,166:INFO:Calculating mean and std
2024-08-31 23:17:37,167:INFO:Creating metrics dataframe
2024-08-31 23:17:37,168:INFO:Uploading results into container
2024-08-31 23:17:37,168:INFO:Uploading model into container now
2024-08-31 23:17:37,169:INFO:_master_model_container: 5
2024-08-31 23:17:37,169:INFO:_display_container: 2
2024-08-31 23:17:37,169:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-31 23:17:37,169:INFO:create_model() successfully completed......................................
2024-08-31 23:17:37,226:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:37,226:INFO:Creating metrics dataframe
2024-08-31 23:17:37,230:INFO:Initializing SVM - Linear Kernel
2024-08-31 23:17:37,230:INFO:Total runtime is 0.06250900030136108 minutes
2024-08-31 23:17:37,231:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:37,231:INFO:Initializing create_model()
2024-08-31 23:17:37,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:37,231:INFO:Checking exceptions
2024-08-31 23:17:37,231:INFO:Importing libraries
2024-08-31 23:17:37,231:INFO:Copying training dataset
2024-08-31 23:17:37,233:INFO:Defining folds
2024-08-31 23:17:37,233:INFO:Declaring metric variables
2024-08-31 23:17:37,234:INFO:Importing untrained model
2024-08-31 23:17:37,235:INFO:SVM - Linear Kernel Imported successfully
2024-08-31 23:17:37,237:INFO:Starting cross validation
2024-08-31 23:17:37,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:37,365:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,366:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,380:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,381:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,383:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,383:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,384:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,387:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,388:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,401:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,405:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,406:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,427:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,428:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,441:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,442:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,442:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,443:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,445:INFO:Calculating mean and std
2024-08-31 23:17:37,445:INFO:Creating metrics dataframe
2024-08-31 23:17:37,446:INFO:Uploading results into container
2024-08-31 23:17:37,447:INFO:Uploading model into container now
2024-08-31 23:17:37,447:INFO:_master_model_container: 6
2024-08-31 23:17:37,447:INFO:_display_container: 2
2024-08-31 23:17:37,447:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-31 23:17:37,447:INFO:create_model() successfully completed......................................
2024-08-31 23:17:37,500:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:37,500:INFO:Creating metrics dataframe
2024-08-31 23:17:37,504:INFO:Initializing Ridge Classifier
2024-08-31 23:17:37,504:INFO:Total runtime is 0.0670741319656372 minutes
2024-08-31 23:17:37,505:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:37,505:INFO:Initializing create_model()
2024-08-31 23:17:37,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:37,505:INFO:Checking exceptions
2024-08-31 23:17:37,505:INFO:Importing libraries
2024-08-31 23:17:37,505:INFO:Copying training dataset
2024-08-31 23:17:37,507:INFO:Defining folds
2024-08-31 23:17:37,507:INFO:Declaring metric variables
2024-08-31 23:17:37,508:INFO:Importing untrained model
2024-08-31 23:17:37,509:INFO:Ridge Classifier Imported successfully
2024-08-31 23:17:37,510:INFO:Starting cross validation
2024-08-31 23:17:37,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:37,585:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,586:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,590:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,590:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,591:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,594:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,599:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,602:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,607:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,608:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,610:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,612:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,617:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,618:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,625:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,626:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,646:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,647:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,657:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:37,658:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:37,660:INFO:Calculating mean and std
2024-08-31 23:17:37,661:INFO:Creating metrics dataframe
2024-08-31 23:17:37,662:INFO:Uploading results into container
2024-08-31 23:17:37,662:INFO:Uploading model into container now
2024-08-31 23:17:37,662:INFO:_master_model_container: 7
2024-08-31 23:17:37,662:INFO:_display_container: 2
2024-08-31 23:17:37,662:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-31 23:17:37,662:INFO:create_model() successfully completed......................................
2024-08-31 23:17:37,714:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:37,714:INFO:Creating metrics dataframe
2024-08-31 23:17:37,719:INFO:Initializing Random Forest Classifier
2024-08-31 23:17:37,719:INFO:Total runtime is 0.07065218687057495 minutes
2024-08-31 23:17:37,720:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:37,720:INFO:Initializing create_model()
2024-08-31 23:17:37,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:37,720:INFO:Checking exceptions
2024-08-31 23:17:37,720:INFO:Importing libraries
2024-08-31 23:17:37,720:INFO:Copying training dataset
2024-08-31 23:17:37,722:INFO:Defining folds
2024-08-31 23:17:37,722:INFO:Declaring metric variables
2024-08-31 23:17:37,723:INFO:Importing untrained model
2024-08-31 23:17:37,724:INFO:Random Forest Classifier Imported successfully
2024-08-31 23:17:37,725:INFO:Starting cross validation
2024-08-31 23:17:37,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:38,185:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:17:38,187:INFO:Calculating mean and std
2024-08-31 23:17:38,187:INFO:Creating metrics dataframe
2024-08-31 23:17:38,189:INFO:Uploading results into container
2024-08-31 23:17:38,189:INFO:Uploading model into container now
2024-08-31 23:17:38,189:INFO:_master_model_container: 8
2024-08-31 23:17:38,189:INFO:_display_container: 2
2024-08-31 23:17:38,189:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-31 23:17:38,189:INFO:create_model() successfully completed......................................
2024-08-31 23:17:38,242:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:38,243:INFO:Creating metrics dataframe
2024-08-31 23:17:38,246:INFO:Initializing Quadratic Discriminant Analysis
2024-08-31 23:17:38,246:INFO:Total runtime is 0.0794447660446167 minutes
2024-08-31 23:17:38,247:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:38,247:INFO:Initializing create_model()
2024-08-31 23:17:38,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:38,248:INFO:Checking exceptions
2024-08-31 23:17:38,248:INFO:Importing libraries
2024-08-31 23:17:38,248:INFO:Copying training dataset
2024-08-31 23:17:38,249:INFO:Defining folds
2024-08-31 23:17:38,249:INFO:Declaring metric variables
2024-08-31 23:17:38,250:INFO:Importing untrained model
2024-08-31 23:17:38,251:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-31 23:17:38,252:INFO:Starting cross validation
2024-08-31 23:17:38,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:38,310:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,316:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,330:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,332:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,336:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,337:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,338:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,341:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,343:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,351:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,358:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,359:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,363:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,374:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,374:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,375:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,385:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,388:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:17:38,398:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,401:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,405:INFO:Calculating mean and std
2024-08-31 23:17:38,405:INFO:Creating metrics dataframe
2024-08-31 23:17:38,407:INFO:Uploading results into container
2024-08-31 23:17:38,407:INFO:Uploading model into container now
2024-08-31 23:17:38,407:INFO:_master_model_container: 9
2024-08-31 23:17:38,407:INFO:_display_container: 2
2024-08-31 23:17:38,407:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-31 23:17:38,407:INFO:create_model() successfully completed......................................
2024-08-31 23:17:38,465:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:38,465:INFO:Creating metrics dataframe
2024-08-31 23:17:38,468:INFO:Initializing Ada Boost Classifier
2024-08-31 23:17:38,469:INFO:Total runtime is 0.08315133253733317 minutes
2024-08-31 23:17:38,470:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:38,470:INFO:Initializing create_model()
2024-08-31 23:17:38,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:38,470:INFO:Checking exceptions
2024-08-31 23:17:38,470:INFO:Importing libraries
2024-08-31 23:17:38,470:INFO:Copying training dataset
2024-08-31 23:17:38,472:INFO:Defining folds
2024-08-31 23:17:38,472:INFO:Declaring metric variables
2024-08-31 23:17:38,473:INFO:Importing untrained model
2024-08-31 23:17:38,473:INFO:Ada Boost Classifier Imported successfully
2024-08-31 23:17:38,475:INFO:Starting cross validation
2024-08-31 23:17:38,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:38,536:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,539:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,542:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,544:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,552:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,562:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,572:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,593:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,645:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,648:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,652:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,668:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,672:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,673:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,677:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,689:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,691:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,692:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:17:38,757:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,758:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:38,762:INFO:Calculating mean and std
2024-08-31 23:17:38,762:INFO:Creating metrics dataframe
2024-08-31 23:17:38,764:INFO:Uploading results into container
2024-08-31 23:17:38,764:INFO:Uploading model into container now
2024-08-31 23:17:38,764:INFO:_master_model_container: 10
2024-08-31 23:17:38,764:INFO:_display_container: 2
2024-08-31 23:17:38,764:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-08-31 23:17:38,764:INFO:create_model() successfully completed......................................
2024-08-31 23:17:38,821:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:38,821:INFO:Creating metrics dataframe
2024-08-31 23:17:38,825:INFO:Initializing Gradient Boosting Classifier
2024-08-31 23:17:38,825:INFO:Total runtime is 0.08909048239390055 minutes
2024-08-31 23:17:38,826:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:38,826:INFO:Initializing create_model()
2024-08-31 23:17:38,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:38,826:INFO:Checking exceptions
2024-08-31 23:17:38,826:INFO:Importing libraries
2024-08-31 23:17:38,826:INFO:Copying training dataset
2024-08-31 23:17:38,828:INFO:Defining folds
2024-08-31 23:17:38,828:INFO:Declaring metric variables
2024-08-31 23:17:38,829:INFO:Importing untrained model
2024-08-31 23:17:38,830:INFO:Gradient Boosting Classifier Imported successfully
2024-08-31 23:17:38,832:INFO:Starting cross validation
2024-08-31 23:17:38,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:39,778:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,779:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,780:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,782:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,787:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,788:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,811:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:39,829:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,432:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,434:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,437:INFO:Calculating mean and std
2024-08-31 23:17:40,438:INFO:Creating metrics dataframe
2024-08-31 23:17:40,439:INFO:Uploading results into container
2024-08-31 23:17:40,439:INFO:Uploading model into container now
2024-08-31 23:17:40,440:INFO:_master_model_container: 11
2024-08-31 23:17:40,440:INFO:_display_container: 2
2024-08-31 23:17:40,440:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-31 23:17:40,440:INFO:create_model() successfully completed......................................
2024-08-31 23:17:40,494:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:40,494:INFO:Creating metrics dataframe
2024-08-31 23:17:40,498:INFO:Initializing Linear Discriminant Analysis
2024-08-31 23:17:40,498:INFO:Total runtime is 0.11697233517964681 minutes
2024-08-31 23:17:40,499:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:40,499:INFO:Initializing create_model()
2024-08-31 23:17:40,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:40,499:INFO:Checking exceptions
2024-08-31 23:17:40,499:INFO:Importing libraries
2024-08-31 23:17:40,499:INFO:Copying training dataset
2024-08-31 23:17:40,500:INFO:Defining folds
2024-08-31 23:17:40,500:INFO:Declaring metric variables
2024-08-31 23:17:40,501:INFO:Importing untrained model
2024-08-31 23:17:40,502:INFO:Linear Discriminant Analysis Imported successfully
2024-08-31 23:17:40,504:INFO:Starting cross validation
2024-08-31 23:17:40,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:40,570:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,576:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,605:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,607:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,608:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,612:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,620:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,628:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,650:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,653:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:17:40,657:INFO:Calculating mean and std
2024-08-31 23:17:40,657:INFO:Creating metrics dataframe
2024-08-31 23:17:40,659:INFO:Uploading results into container
2024-08-31 23:17:40,659:INFO:Uploading model into container now
2024-08-31 23:17:40,659:INFO:_master_model_container: 12
2024-08-31 23:17:40,659:INFO:_display_container: 2
2024-08-31 23:17:40,659:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-31 23:17:40,659:INFO:create_model() successfully completed......................................
2024-08-31 23:17:40,713:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:40,714:INFO:Creating metrics dataframe
2024-08-31 23:17:40,718:INFO:Initializing Extra Trees Classifier
2024-08-31 23:17:40,718:INFO:Total runtime is 0.120646599928538 minutes
2024-08-31 23:17:40,719:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:40,720:INFO:Initializing create_model()
2024-08-31 23:17:40,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:40,720:INFO:Checking exceptions
2024-08-31 23:17:40,720:INFO:Importing libraries
2024-08-31 23:17:40,720:INFO:Copying training dataset
2024-08-31 23:17:40,721:INFO:Defining folds
2024-08-31 23:17:40,721:INFO:Declaring metric variables
2024-08-31 23:17:40,722:INFO:Importing untrained model
2024-08-31 23:17:40,723:INFO:Extra Trees Classifier Imported successfully
2024-08-31 23:17:40,725:INFO:Starting cross validation
2024-08-31 23:17:40,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:41,160:INFO:Calculating mean and std
2024-08-31 23:17:41,160:INFO:Creating metrics dataframe
2024-08-31 23:17:41,161:INFO:Uploading results into container
2024-08-31 23:17:41,162:INFO:Uploading model into container now
2024-08-31 23:17:41,162:INFO:_master_model_container: 13
2024-08-31 23:17:41,162:INFO:_display_container: 2
2024-08-31 23:17:41,162:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-31 23:17:41,162:INFO:create_model() successfully completed......................................
2024-08-31 23:17:41,216:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:41,216:INFO:Creating metrics dataframe
2024-08-31 23:17:41,220:INFO:Initializing Extreme Gradient Boosting
2024-08-31 23:17:41,220:INFO:Total runtime is 0.12900431553522745 minutes
2024-08-31 23:17:41,221:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:41,221:INFO:Initializing create_model()
2024-08-31 23:17:41,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:41,221:INFO:Checking exceptions
2024-08-31 23:17:41,221:INFO:Importing libraries
2024-08-31 23:17:41,221:INFO:Copying training dataset
2024-08-31 23:17:41,222:INFO:Defining folds
2024-08-31 23:17:41,222:INFO:Declaring metric variables
2024-08-31 23:17:41,223:INFO:Importing untrained model
2024-08-31 23:17:41,224:INFO:Extreme Gradient Boosting Imported successfully
2024-08-31 23:17:41,226:INFO:Starting cross validation
2024-08-31 23:17:41,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:17:41,650:INFO:Calculating mean and std
2024-08-31 23:17:41,651:INFO:Creating metrics dataframe
2024-08-31 23:17:41,652:INFO:Uploading results into container
2024-08-31 23:17:41,652:INFO:Uploading model into container now
2024-08-31 23:17:41,653:INFO:_master_model_container: 14
2024-08-31 23:17:41,653:INFO:_display_container: 2
2024-08-31 23:17:41,653:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-08-31 23:17:41,653:INFO:create_model() successfully completed......................................
2024-08-31 23:17:41,705:INFO:SubProcess create_model() end ==================================
2024-08-31 23:17:41,705:INFO:Creating metrics dataframe
2024-08-31 23:17:41,710:INFO:Initializing Light Gradient Boosting Machine
2024-08-31 23:17:41,710:INFO:Total runtime is 0.1371690034866333 minutes
2024-08-31 23:17:41,711:INFO:SubProcess create_model() called ==================================
2024-08-31 23:17:41,711:INFO:Initializing create_model()
2024-08-31 23:17:41,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:17:41,711:INFO:Checking exceptions
2024-08-31 23:17:41,711:INFO:Importing libraries
2024-08-31 23:17:41,711:INFO:Copying training dataset
2024-08-31 23:17:41,712:INFO:Defining folds
2024-08-31 23:17:41,712:INFO:Declaring metric variables
2024-08-31 23:17:41,713:INFO:Importing untrained model
2024-08-31 23:17:41,714:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-31 23:17:41,716:INFO:Starting cross validation
2024-08-31 23:17:41,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:18:03,327:INFO:Calculating mean and std
2024-08-31 23:18:03,328:INFO:Creating metrics dataframe
2024-08-31 23:18:03,331:INFO:Uploading results into container
2024-08-31 23:18:03,331:INFO:Uploading model into container now
2024-08-31 23:18:03,332:INFO:_master_model_container: 15
2024-08-31 23:18:03,332:INFO:_display_container: 2
2024-08-31 23:18:03,332:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-31 23:18:03,332:INFO:create_model() successfully completed......................................
2024-08-31 23:18:03,439:INFO:SubProcess create_model() end ==================================
2024-08-31 23:18:03,439:INFO:Creating metrics dataframe
2024-08-31 23:18:03,443:INFO:Initializing CatBoost Classifier
2024-08-31 23:18:03,444:INFO:Total runtime is 0.4994013508160909 minutes
2024-08-31 23:18:03,445:INFO:SubProcess create_model() called ==================================
2024-08-31 23:18:03,445:INFO:Initializing create_model()
2024-08-31 23:18:03,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:18:03,445:INFO:Checking exceptions
2024-08-31 23:18:03,445:INFO:Importing libraries
2024-08-31 23:18:03,445:INFO:Copying training dataset
2024-08-31 23:18:03,447:INFO:Defining folds
2024-08-31 23:18:03,447:INFO:Declaring metric variables
2024-08-31 23:18:03,448:INFO:Importing untrained model
2024-08-31 23:18:03,449:INFO:CatBoost Classifier Imported successfully
2024-08-31 23:18:03,451:INFO:Starting cross validation
2024-08-31 23:18:03,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:18:08,622:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,624:INFO:Calculating mean and std
2024-08-31 23:18:08,625:INFO:Creating metrics dataframe
2024-08-31 23:18:08,626:INFO:Uploading results into container
2024-08-31 23:18:08,627:INFO:Uploading model into container now
2024-08-31 23:18:08,627:INFO:_master_model_container: 16
2024-08-31 23:18:08,627:INFO:_display_container: 2
2024-08-31 23:18:08,627:INFO:<catboost.core.CatBoostClassifier object at 0x1772bc890>
2024-08-31 23:18:08,627:INFO:create_model() successfully completed......................................
2024-08-31 23:18:08,705:INFO:SubProcess create_model() end ==================================
2024-08-31 23:18:08,705:INFO:Creating metrics dataframe
2024-08-31 23:18:08,709:INFO:Initializing Dummy Classifier
2024-08-31 23:18:08,709:INFO:Total runtime is 0.5871660312016804 minutes
2024-08-31 23:18:08,711:INFO:SubProcess create_model() called ==================================
2024-08-31 23:18:08,711:INFO:Initializing create_model()
2024-08-31 23:18:08,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16dec8210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:18:08,711:INFO:Checking exceptions
2024-08-31 23:18:08,711:INFO:Importing libraries
2024-08-31 23:18:08,711:INFO:Copying training dataset
2024-08-31 23:18:08,713:INFO:Defining folds
2024-08-31 23:18:08,713:INFO:Declaring metric variables
2024-08-31 23:18:08,714:INFO:Importing untrained model
2024-08-31 23:18:08,715:INFO:Dummy Classifier Imported successfully
2024-08-31 23:18:08,717:INFO:Starting cross validation
2024-08-31 23:18:08,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:18:08,809:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,821:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,824:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,825:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,837:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,838:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,842:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,853:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,868:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,875:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:18:08,878:INFO:Calculating mean and std
2024-08-31 23:18:08,880:INFO:Creating metrics dataframe
2024-08-31 23:18:08,881:INFO:Uploading results into container
2024-08-31 23:18:08,881:INFO:Uploading model into container now
2024-08-31 23:18:08,882:INFO:_master_model_container: 17
2024-08-31 23:18:08,882:INFO:_display_container: 2
2024-08-31 23:18:08,882:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-08-31 23:18:08,882:INFO:create_model() successfully completed......................................
2024-08-31 23:18:08,949:INFO:SubProcess create_model() end ==================================
2024-08-31 23:18:08,949:INFO:Creating metrics dataframe
2024-08-31 23:18:08,957:INFO:Initializing create_model()
2024-08-31 23:18:08,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16a866350>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:18:08,957:INFO:Checking exceptions
2024-08-31 23:18:08,958:INFO:Importing libraries
2024-08-31 23:18:08,958:INFO:Copying training dataset
2024-08-31 23:18:08,959:INFO:Defining folds
2024-08-31 23:18:08,959:INFO:Declaring metric variables
2024-08-31 23:18:08,959:INFO:Importing untrained model
2024-08-31 23:18:08,960:INFO:Declaring custom model
2024-08-31 23:18:08,960:INFO:Logistic Regression Imported successfully
2024-08-31 23:18:08,960:INFO:Cross validation set to False
2024-08-31 23:18:08,960:INFO:Fitting Model
2024-08-31 23:18:09,142:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 23:18:09,142:INFO:create_model() successfully completed......................................
2024-08-31 23:18:09,205:INFO:_master_model_container: 17
2024-08-31 23:18:09,206:INFO:_display_container: 2
2024-08-31 23:18:09,206:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 23:18:09,206:INFO:compare_models() successfully completed......................................
2024-08-31 23:18:09,236:INFO:Initializing save_model()
2024-08-31 23:18:09,237:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-31 23:18:09,237:INFO:Adding model into prep_pipe
2024-08-31 23:18:09,241:INFO:student_performance_model.pkl saved in current working directory
2024-08-31 23:18:09,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Gender...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-08-31 23:18:09,269:INFO:save_model() successfully completed......................................
2024-08-31 23:18:09,364:INFO:Soft dependency imported: fastapi: 0.112.2
2024-08-31 23:18:09,364:ERROR:
'uvicorn' is a soft dependency and not included in the pycaret installation. Please run: `pip install uvicorn` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-08-31 23:18:39,288:INFO:Soft dependency imported: fastapi: 0.112.2
2024-08-31 23:18:39,290:ERROR:
'uvicorn' is a soft dependency and not included in the pycaret installation. Please run: `pip install uvicorn` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-08-31 23:19:17,871:INFO:Soft dependency imported: fastapi: 0.112.2
2024-08-31 23:19:17,872:ERROR:
'uvicorn' is a soft dependency and not included in the pycaret installation. Please run: `pip install uvicorn` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-08-31 23:19:42,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:19:42,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:19:42,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:19:42,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:19:46,321:INFO:PyCaret ClassificationExperiment
2024-08-31 23:19:46,321:INFO:Logging name: clf-default-name
2024-08-31 23:19:46,321:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-31 23:19:46,322:INFO:version 3.3.2
2024-08-31 23:19:46,322:INFO:Initializing setup()
2024-08-31 23:19:46,322:INFO:self.USI: b290
2024-08-31 23:19:46,322:INFO:self._variable_keys: {'fold_generator', 'y', 'html_param', 'X', 'exp_id', 'memory', 'is_multiclass', 'exp_name_log', 'n_jobs_param', 'gpu_param', '_ml_usecase', 'X_train', 'seed', 'fold_shuffle_param', '_available_plots', 'USI', 'data', 'y_train', 'fix_imbalance', 'target_param', 'logging_param', 'X_test', 'gpu_n_jobs_param', 'fold_groups_param', 'pipeline', 'y_test', 'log_plots_param', 'idx'}
2024-08-31 23:19:46,322:INFO:Checking environment
2024-08-31 23:19:46,322:INFO:python_version: 3.11.5
2024-08-31 23:19:46,322:INFO:python_build: ('main', 'Sep 11 2023 08:17:37')
2024-08-31 23:19:46,322:INFO:machine: arm64
2024-08-31 23:19:46,322:INFO:platform: macOS-13.2.1-arm64-arm-64bit
2024-08-31 23:19:46,322:INFO:Memory: svmem(total=8589934592, available=2931621888, percent=65.9, used=3133505536, free=1103724544, active=1790951424, inactive=1704411136, wired=1342554112)
2024-08-31 23:19:46,323:INFO:Physical Core: 8
2024-08-31 23:19:46,323:INFO:Logical Core: 8
2024-08-31 23:19:46,323:INFO:Checking libraries
2024-08-31 23:19:46,323:INFO:System:
2024-08-31 23:19:46,323:INFO:    python: 3.11.5 (main, Sep 11 2023, 08:17:37) [Clang 14.0.6 ]
2024-08-31 23:19:46,323:INFO:executable: /Users/fady/anaconda3/bin/python
2024-08-31 23:19:46,323:INFO:   machine: macOS-13.2.1-arm64-arm-64bit
2024-08-31 23:19:46,323:INFO:PyCaret required dependencies:
2024-08-31 23:19:46,450:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:46,601:INFO:                 pip: 23.2.1
2024-08-31 23:19:46,602:INFO:          setuptools: 68.0.0
2024-08-31 23:19:46,602:INFO:             pycaret: 3.3.2
2024-08-31 23:19:46,602:INFO:             IPython: 8.20.0
2024-08-31 23:19:46,602:INFO:          ipywidgets: 8.1.2
2024-08-31 23:19:46,602:INFO:                tqdm: 4.65.0
2024-08-31 23:19:46,602:INFO:               numpy: 1.26.4
2024-08-31 23:19:46,602:INFO:              pandas: 1.5.3
2024-08-31 23:19:46,602:INFO:              jinja2: 3.0.3
2024-08-31 23:19:46,602:INFO:               scipy: 1.10.0
2024-08-31 23:19:46,602:INFO:              joblib: 1.2.0
2024-08-31 23:19:46,602:INFO:             sklearn: 1.4.2
2024-08-31 23:19:46,602:INFO:                pyod: 2.0.1
2024-08-31 23:19:46,602:INFO:            imblearn: 0.12.3
2024-08-31 23:19:46,602:INFO:   category_encoders: 2.6.3
2024-08-31 23:19:46,602:INFO:            lightgbm: 4.5.0
2024-08-31 23:19:46,602:INFO:               numba: 0.59.0
2024-08-31 23:19:46,602:INFO:            requests: 2.31.0
2024-08-31 23:19:46,602:INFO:          matplotlib: 3.7.5
2024-08-31 23:19:46,602:INFO:          scikitplot: 0.3.7
2024-08-31 23:19:46,602:INFO:         yellowbrick: 1.5
2024-08-31 23:19:46,602:INFO:              plotly: 5.19.0
2024-08-31 23:19:46,602:INFO:    plotly-resampler: Not installed
2024-08-31 23:19:46,602:INFO:             kaleido: 0.2.1
2024-08-31 23:19:46,602:INFO:           schemdraw: 0.15
2024-08-31 23:19:46,602:INFO:         statsmodels: 0.14.0
2024-08-31 23:19:46,602:INFO:              sktime: 0.26.0
2024-08-31 23:19:46,602:INFO:               tbats: 1.1.3
2024-08-31 23:19:46,602:INFO:            pmdarima: 2.0.4
2024-08-31 23:19:46,602:INFO:              psutil: 5.9.0
2024-08-31 23:19:46,602:INFO:          markupsafe: 2.1.3
2024-08-31 23:19:46,602:INFO:             pickle5: Not installed
2024-08-31 23:19:46,602:INFO:         cloudpickle: 2.2.1
2024-08-31 23:19:46,602:INFO:         deprecation: 2.1.0
2024-08-31 23:19:46,602:INFO:              xxhash: 2.0.2
2024-08-31 23:19:46,602:INFO:           wurlitzer: 3.0.2
2024-08-31 23:19:46,602:INFO:PyCaret optional dependencies:
2024-08-31 23:19:46,716:INFO:                shap: Not installed
2024-08-31 23:19:46,716:INFO:           interpret: Not installed
2024-08-31 23:19:46,716:INFO:                umap: Not installed
2024-08-31 23:19:46,716:INFO:     ydata_profiling: Not installed
2024-08-31 23:19:46,716:INFO:  explainerdashboard: Not installed
2024-08-31 23:19:46,716:INFO:             autoviz: Not installed
2024-08-31 23:19:46,716:INFO:           fairlearn: Not installed
2024-08-31 23:19:46,716:INFO:          deepchecks: Not installed
2024-08-31 23:19:46,716:INFO:             xgboost: 2.0.3
2024-08-31 23:19:46,716:INFO:            catboost: 1.2
2024-08-31 23:19:46,716:INFO:              kmodes: Not installed
2024-08-31 23:19:46,716:INFO:             mlxtend: Not installed
2024-08-31 23:19:46,716:INFO:       statsforecast: Not installed
2024-08-31 23:19:46,716:INFO:        tune_sklearn: Not installed
2024-08-31 23:19:46,716:INFO:                 ray: Not installed
2024-08-31 23:19:46,716:INFO:            hyperopt: Not installed
2024-08-31 23:19:46,716:INFO:              optuna: Not installed
2024-08-31 23:19:46,716:INFO:               skopt: Not installed
2024-08-31 23:19:46,716:INFO:              mlflow: Not installed
2024-08-31 23:19:46,716:INFO:              gradio: Not installed
2024-08-31 23:19:46,716:INFO:             fastapi: 0.112.2
2024-08-31 23:19:46,716:INFO:             uvicorn: 0.30.6
2024-08-31 23:19:46,716:INFO:              m2cgen: Not installed
2024-08-31 23:19:46,716:INFO:           evidently: Not installed
2024-08-31 23:19:46,716:INFO:               fugue: Not installed
2024-08-31 23:19:46,716:INFO:           streamlit: Not installed
2024-08-31 23:19:46,716:INFO:             prophet: Not installed
2024-08-31 23:19:46,716:INFO:None
2024-08-31 23:19:46,716:INFO:Set up data.
2024-08-31 23:19:46,718:INFO:Set up folding strategy.
2024-08-31 23:19:46,718:INFO:Set up train/test split.
2024-08-31 23:19:46,720:INFO:Set up index.
2024-08-31 23:19:46,720:INFO:Assigning column types.
2024-08-31 23:19:46,721:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-31 23:19:46,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 23:19:46,738:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:19:46,750:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:46,751:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:46,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-31 23:19:46,780:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:19:46,790:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:46,791:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:46,791:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-31 23:19:46,808:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:19:46,818:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:46,819:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:46,836:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-31 23:19:46,846:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:46,847:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:46,847:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-31 23:19:46,874:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:46,875:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:46,901:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:46,902:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:46,903:INFO:Preparing preprocessing pipeline...
2024-08-31 23:19:46,904:INFO:Set up simple imputation.
2024-08-31 23:19:46,905:INFO:Set up encoding of ordinal features.
2024-08-31 23:19:46,906:INFO:Set up encoding of categorical features.
2024-08-31 23:19:46,940:INFO:Finished creating preprocessing pipeline.
2024-08-31 23:19:46,966:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-31 23:19:46,966:INFO:Creating final display dataframe.
2024-08-31 23:19:47,040:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        GradeClass
2                   Target type        Multiclass
3           Original data shape        (2392, 15)
4        Transformed data shape        (2392, 24)
5   Transformed train set shape        (1674, 24)
6    Transformed test set shape         (718, 24)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 9
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              b290
2024-08-31 23:19:47,069:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:47,070:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:47,097:INFO:Soft dependency imported: xgboost: 2.0.3
2024-08-31 23:19:47,098:INFO:Soft dependency imported: catboost: 1.2
2024-08-31 23:19:47,099:INFO:setup() successfully completed in 0.78s...............
2024-08-31 23:19:47,432:INFO:Initializing compare_models()
2024-08-31 23:19:47,433:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-31 23:19:47,433:INFO:Checking exceptions
2024-08-31 23:19:47,438:INFO:Preparing display monitor
2024-08-31 23:19:47,478:INFO:Initializing Logistic Regression
2024-08-31 23:19:47,478:INFO:Total runtime is 3.0835469563802084e-06 minutes
2024-08-31 23:19:47,480:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:47,481:INFO:Initializing create_model()
2024-08-31 23:19:47,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:47,481:INFO:Checking exceptions
2024-08-31 23:19:47,481:INFO:Importing libraries
2024-08-31 23:19:47,482:INFO:Copying training dataset
2024-08-31 23:19:47,484:INFO:Defining folds
2024-08-31 23:19:47,484:INFO:Declaring metric variables
2024-08-31 23:19:47,486:INFO:Importing untrained model
2024-08-31 23:19:47,488:INFO:Logistic Regression Imported successfully
2024-08-31 23:19:47,490:INFO:Starting cross validation
2024-08-31 23:19:47,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:49,272:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,274:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,280:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,286:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,299:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,345:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,375:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,439:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:19:49,861:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:49,867:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:49,868:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 23:19:49,886:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:49,910:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:49,913:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:49,921:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 23:19:49,942:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-31 23:19:49,942:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:49,963:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:50,000:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:50,100:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:50,146:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:50,149:INFO:Calculating mean and std
2024-08-31 23:19:50,151:INFO:Creating metrics dataframe
2024-08-31 23:19:50,153:INFO:Uploading results into container
2024-08-31 23:19:50,154:INFO:Uploading model into container now
2024-08-31 23:19:50,154:INFO:_master_model_container: 1
2024-08-31 23:19:50,154:INFO:_display_container: 2
2024-08-31 23:19:50,154:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 23:19:50,154:INFO:create_model() successfully completed......................................
2024-08-31 23:19:50,223:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:50,223:INFO:Creating metrics dataframe
2024-08-31 23:19:50,226:INFO:Initializing K Neighbors Classifier
2024-08-31 23:19:50,226:INFO:Total runtime is 0.04579663276672363 minutes
2024-08-31 23:19:50,227:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:50,227:INFO:Initializing create_model()
2024-08-31 23:19:50,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:50,227:INFO:Checking exceptions
2024-08-31 23:19:50,228:INFO:Importing libraries
2024-08-31 23:19:50,228:INFO:Copying training dataset
2024-08-31 23:19:50,229:INFO:Defining folds
2024-08-31 23:19:50,229:INFO:Declaring metric variables
2024-08-31 23:19:50,230:INFO:Importing untrained model
2024-08-31 23:19:50,231:INFO:K Neighbors Classifier Imported successfully
2024-08-31 23:19:50,232:INFO:Starting cross validation
2024-08-31 23:19:50,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:50,333:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,335:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,338:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,346:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,348:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,348:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,354:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,356:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,358:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,358:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,360:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,361:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,366:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,366:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,367:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,370:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,399:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,400:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,403:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,404:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,405:INFO:Calculating mean and std
2024-08-31 23:19:50,406:INFO:Creating metrics dataframe
2024-08-31 23:19:50,407:INFO:Uploading results into container
2024-08-31 23:19:50,407:INFO:Uploading model into container now
2024-08-31 23:19:50,407:INFO:_master_model_container: 2
2024-08-31 23:19:50,408:INFO:_display_container: 2
2024-08-31 23:19:50,408:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 23:19:50,408:INFO:create_model() successfully completed......................................
2024-08-31 23:19:50,456:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-31 23:19:50,457:WARNING:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-08-31 23:19:50,458:INFO:Initializing create_model()
2024-08-31 23:19:50,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:50,458:INFO:Checking exceptions
2024-08-31 23:19:50,458:INFO:Importing libraries
2024-08-31 23:19:50,458:INFO:Copying training dataset
2024-08-31 23:19:50,459:INFO:Defining folds
2024-08-31 23:19:50,459:INFO:Declaring metric variables
2024-08-31 23:19:50,460:INFO:Importing untrained model
2024-08-31 23:19:50,461:INFO:K Neighbors Classifier Imported successfully
2024-08-31 23:19:50,463:INFO:Starting cross validation
2024-08-31 23:19:50,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:50,529:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,540:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,540:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,545:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,549:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,551:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,553:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,556:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,557:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,557:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,558:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,560:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,562:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,566:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,577:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,582:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,589:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,593:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,596:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 338, in predict_proba
    return self.steps[-1][1].predict_proba(Xt, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 366, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,600:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py", line 850, in kneighbors
    results = ArgKmin.compute(
              ^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 278, in compute
    return ArgKmin64.compute(
           ^^^^^^^^^^^^^^^^^^
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 90, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py", line 94, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 371, in _load_modules
    self._find_modules_with_dyld()
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 428, in _find_modules_with_dyld
    self._make_module_from_path(filepath)
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
                   ^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/threadpoolctl.py", line 646, in get_version
    config = get_config().split()
             ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2024-08-31 23:19:50,601:INFO:Calculating mean and std
2024-08-31 23:19:50,601:INFO:Creating metrics dataframe
2024-08-31 23:19:50,603:INFO:Uploading results into container
2024-08-31 23:19:50,603:INFO:Uploading model into container now
2024-08-31 23:19:50,603:INFO:_master_model_container: 3
2024-08-31 23:19:50,603:INFO:_display_container: 2
2024-08-31 23:19:50,603:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-31 23:19:50,603:INFO:create_model() successfully completed......................................
2024-08-31 23:19:50,652:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2024-08-31 23:19:50,652:ERROR:Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-08-31 23:19:50,652:INFO:Initializing Naive Bayes
2024-08-31 23:19:50,652:INFO:Total runtime is 0.052899364630381265 minutes
2024-08-31 23:19:50,653:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:50,654:INFO:Initializing create_model()
2024-08-31 23:19:50,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:50,654:INFO:Checking exceptions
2024-08-31 23:19:50,654:INFO:Importing libraries
2024-08-31 23:19:50,654:INFO:Copying training dataset
2024-08-31 23:19:50,655:INFO:Defining folds
2024-08-31 23:19:50,655:INFO:Declaring metric variables
2024-08-31 23:19:50,656:INFO:Importing untrained model
2024-08-31 23:19:50,657:INFO:Naive Bayes Imported successfully
2024-08-31 23:19:50,659:INFO:Starting cross validation
2024-08-31 23:19:50,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:50,741:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,741:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,741:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,746:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,751:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,756:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,766:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,771:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,794:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,795:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:50,797:INFO:Calculating mean and std
2024-08-31 23:19:50,797:INFO:Creating metrics dataframe
2024-08-31 23:19:50,799:INFO:Uploading results into container
2024-08-31 23:19:50,799:INFO:Uploading model into container now
2024-08-31 23:19:50,799:INFO:_master_model_container: 4
2024-08-31 23:19:50,799:INFO:_display_container: 2
2024-08-31 23:19:50,800:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-31 23:19:50,800:INFO:create_model() successfully completed......................................
2024-08-31 23:19:50,864:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:50,864:INFO:Creating metrics dataframe
2024-08-31 23:19:50,867:INFO:Initializing Decision Tree Classifier
2024-08-31 23:19:50,868:INFO:Total runtime is 0.05648691654205322 minutes
2024-08-31 23:19:50,869:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:50,869:INFO:Initializing create_model()
2024-08-31 23:19:50,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:50,869:INFO:Checking exceptions
2024-08-31 23:19:50,869:INFO:Importing libraries
2024-08-31 23:19:50,869:INFO:Copying training dataset
2024-08-31 23:19:50,870:INFO:Defining folds
2024-08-31 23:19:50,870:INFO:Declaring metric variables
2024-08-31 23:19:50,871:INFO:Importing untrained model
2024-08-31 23:19:50,872:INFO:Decision Tree Classifier Imported successfully
2024-08-31 23:19:50,874:INFO:Starting cross validation
2024-08-31 23:19:50,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:51,026:INFO:Calculating mean and std
2024-08-31 23:19:51,026:INFO:Creating metrics dataframe
2024-08-31 23:19:51,027:INFO:Uploading results into container
2024-08-31 23:19:51,027:INFO:Uploading model into container now
2024-08-31 23:19:51,028:INFO:_master_model_container: 5
2024-08-31 23:19:51,028:INFO:_display_container: 2
2024-08-31 23:19:51,028:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-31 23:19:51,028:INFO:create_model() successfully completed......................................
2024-08-31 23:19:51,079:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:51,079:INFO:Creating metrics dataframe
2024-08-31 23:19:51,083:INFO:Initializing SVM - Linear Kernel
2024-08-31 23:19:51,083:INFO:Total runtime is 0.060077782471974685 minutes
2024-08-31 23:19:51,084:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:51,084:INFO:Initializing create_model()
2024-08-31 23:19:51,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:51,084:INFO:Checking exceptions
2024-08-31 23:19:51,084:INFO:Importing libraries
2024-08-31 23:19:51,084:INFO:Copying training dataset
2024-08-31 23:19:51,086:INFO:Defining folds
2024-08-31 23:19:51,086:INFO:Declaring metric variables
2024-08-31 23:19:51,087:INFO:Importing untrained model
2024-08-31 23:19:51,088:INFO:SVM - Linear Kernel Imported successfully
2024-08-31 23:19:51,090:INFO:Starting cross validation
2024-08-31 23:19:51,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:51,199:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,200:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,209:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,210:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,224:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,224:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,224:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,225:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,226:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,226:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,239:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,240:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,241:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,241:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,276:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,277:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,279:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,280:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,282:INFO:Calculating mean and std
2024-08-31 23:19:51,283:INFO:Creating metrics dataframe
2024-08-31 23:19:51,284:INFO:Uploading results into container
2024-08-31 23:19:51,284:INFO:Uploading model into container now
2024-08-31 23:19:51,285:INFO:_master_model_container: 6
2024-08-31 23:19:51,285:INFO:_display_container: 2
2024-08-31 23:19:51,285:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-31 23:19:51,285:INFO:create_model() successfully completed......................................
2024-08-31 23:19:51,333:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:51,333:INFO:Creating metrics dataframe
2024-08-31 23:19:51,336:INFO:Initializing Ridge Classifier
2024-08-31 23:19:51,336:INFO:Total runtime is 0.06429893573125203 minutes
2024-08-31 23:19:51,337:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:51,337:INFO:Initializing create_model()
2024-08-31 23:19:51,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:51,338:INFO:Checking exceptions
2024-08-31 23:19:51,338:INFO:Importing libraries
2024-08-31 23:19:51,338:INFO:Copying training dataset
2024-08-31 23:19:51,339:INFO:Defining folds
2024-08-31 23:19:51,339:INFO:Declaring metric variables
2024-08-31 23:19:51,340:INFO:Importing untrained model
2024-08-31 23:19:51,341:INFO:Ridge Classifier Imported successfully
2024-08-31 23:19:51,343:INFO:Starting cross validation
2024-08-31 23:19:51,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:51,416:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,421:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,433:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,433:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,434:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,434:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,437:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,438:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,446:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,447:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,451:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,453:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,453:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,454:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,461:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,463:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,475:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,477:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,484:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:51,485:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,487:INFO:Calculating mean and std
2024-08-31 23:19:51,487:INFO:Creating metrics dataframe
2024-08-31 23:19:51,488:INFO:Uploading results into container
2024-08-31 23:19:51,489:INFO:Uploading model into container now
2024-08-31 23:19:51,489:INFO:_master_model_container: 7
2024-08-31 23:19:51,489:INFO:_display_container: 2
2024-08-31 23:19:51,489:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-31 23:19:51,489:INFO:create_model() successfully completed......................................
2024-08-31 23:19:51,537:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:51,537:INFO:Creating metrics dataframe
2024-08-31 23:19:51,540:INFO:Initializing Random Forest Classifier
2024-08-31 23:19:51,540:INFO:Total runtime is 0.06770048141479491 minutes
2024-08-31 23:19:51,542:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:51,542:INFO:Initializing create_model()
2024-08-31 23:19:51,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:51,542:INFO:Checking exceptions
2024-08-31 23:19:51,542:INFO:Importing libraries
2024-08-31 23:19:51,542:INFO:Copying training dataset
2024-08-31 23:19:51,543:INFO:Defining folds
2024-08-31 23:19:51,543:INFO:Declaring metric variables
2024-08-31 23:19:51,544:INFO:Importing untrained model
2024-08-31 23:19:51,546:INFO:Random Forest Classifier Imported successfully
2024-08-31 23:19:51,547:INFO:Starting cross validation
2024-08-31 23:19:51,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:51,979:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:19:51,981:INFO:Calculating mean and std
2024-08-31 23:19:51,981:INFO:Creating metrics dataframe
2024-08-31 23:19:51,982:INFO:Uploading results into container
2024-08-31 23:19:51,983:INFO:Uploading model into container now
2024-08-31 23:19:51,983:INFO:_master_model_container: 8
2024-08-31 23:19:51,983:INFO:_display_container: 2
2024-08-31 23:19:51,983:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-31 23:19:51,983:INFO:create_model() successfully completed......................................
2024-08-31 23:19:52,030:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:52,030:INFO:Creating metrics dataframe
2024-08-31 23:19:52,034:INFO:Initializing Quadratic Discriminant Analysis
2024-08-31 23:19:52,034:INFO:Total runtime is 0.07592801650365193 minutes
2024-08-31 23:19:52,035:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:52,035:INFO:Initializing create_model()
2024-08-31 23:19:52,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:52,035:INFO:Checking exceptions
2024-08-31 23:19:52,035:INFO:Importing libraries
2024-08-31 23:19:52,035:INFO:Copying training dataset
2024-08-31 23:19:52,037:INFO:Defining folds
2024-08-31 23:19:52,037:INFO:Declaring metric variables
2024-08-31 23:19:52,038:INFO:Importing untrained model
2024-08-31 23:19:52,039:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-31 23:19:52,040:INFO:Starting cross validation
2024-08-31 23:19:52,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:52,083:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,099:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,104:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,104:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,111:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,118:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,129:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,129:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,132:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,138:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,138:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,138:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,149:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,150:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,153:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,157:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,163:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,166:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,172:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-31 23:19:52,184:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,187:INFO:Calculating mean and std
2024-08-31 23:19:52,187:INFO:Creating metrics dataframe
2024-08-31 23:19:52,188:INFO:Uploading results into container
2024-08-31 23:19:52,189:INFO:Uploading model into container now
2024-08-31 23:19:52,189:INFO:_master_model_container: 9
2024-08-31 23:19:52,189:INFO:_display_container: 2
2024-08-31 23:19:52,189:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-31 23:19:52,189:INFO:create_model() successfully completed......................................
2024-08-31 23:19:52,237:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:52,237:INFO:Creating metrics dataframe
2024-08-31 23:19:52,241:INFO:Initializing Ada Boost Classifier
2024-08-31 23:19:52,241:INFO:Total runtime is 0.0793726642926534 minutes
2024-08-31 23:19:52,242:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:52,242:INFO:Initializing create_model()
2024-08-31 23:19:52,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:52,242:INFO:Checking exceptions
2024-08-31 23:19:52,242:INFO:Importing libraries
2024-08-31 23:19:52,242:INFO:Copying training dataset
2024-08-31 23:19:52,244:INFO:Defining folds
2024-08-31 23:19:52,244:INFO:Declaring metric variables
2024-08-31 23:19:52,245:INFO:Importing untrained model
2024-08-31 23:19:52,246:INFO:Ada Boost Classifier Imported successfully
2024-08-31 23:19:52,248:INFO:Starting cross validation
2024-08-31 23:19:52,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:52,298:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,309:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,313:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,328:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,333:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,337:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,340:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,341:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,388:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,399:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,407:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,414:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,422:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,430:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,431:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,434:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,436:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,440:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-31 23:19:52,498:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,502:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:52,505:INFO:Calculating mean and std
2024-08-31 23:19:52,506:INFO:Creating metrics dataframe
2024-08-31 23:19:52,507:INFO:Uploading results into container
2024-08-31 23:19:52,507:INFO:Uploading model into container now
2024-08-31 23:19:52,507:INFO:_master_model_container: 10
2024-08-31 23:19:52,507:INFO:_display_container: 2
2024-08-31 23:19:52,507:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-08-31 23:19:52,507:INFO:create_model() successfully completed......................................
2024-08-31 23:19:52,554:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:52,554:INFO:Creating metrics dataframe
2024-08-31 23:19:52,558:INFO:Initializing Gradient Boosting Classifier
2024-08-31 23:19:52,558:INFO:Total runtime is 0.08465858300526936 minutes
2024-08-31 23:19:52,559:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:52,559:INFO:Initializing create_model()
2024-08-31 23:19:52,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:52,559:INFO:Checking exceptions
2024-08-31 23:19:52,559:INFO:Importing libraries
2024-08-31 23:19:52,559:INFO:Copying training dataset
2024-08-31 23:19:52,560:INFO:Defining folds
2024-08-31 23:19:52,560:INFO:Declaring metric variables
2024-08-31 23:19:52,561:INFO:Importing untrained model
2024-08-31 23:19:52,562:INFO:Gradient Boosting Classifier Imported successfully
2024-08-31 23:19:52,564:INFO:Starting cross validation
2024-08-31 23:19:52,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:53,444:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,458:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,470:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,470:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,478:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,479:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,482:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:53,493:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,105:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,120:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,124:INFO:Calculating mean and std
2024-08-31 23:19:54,124:INFO:Creating metrics dataframe
2024-08-31 23:19:54,125:INFO:Uploading results into container
2024-08-31 23:19:54,125:INFO:Uploading model into container now
2024-08-31 23:19:54,126:INFO:_master_model_container: 11
2024-08-31 23:19:54,126:INFO:_display_container: 2
2024-08-31 23:19:54,126:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-31 23:19:54,126:INFO:create_model() successfully completed......................................
2024-08-31 23:19:54,173:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:54,173:INFO:Creating metrics dataframe
2024-08-31 23:19:54,177:INFO:Initializing Linear Discriminant Analysis
2024-08-31 23:19:54,177:INFO:Total runtime is 0.11163988510767618 minutes
2024-08-31 23:19:54,178:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:54,178:INFO:Initializing create_model()
2024-08-31 23:19:54,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:54,178:INFO:Checking exceptions
2024-08-31 23:19:54,178:INFO:Importing libraries
2024-08-31 23:19:54,178:INFO:Copying training dataset
2024-08-31 23:19:54,179:INFO:Defining folds
2024-08-31 23:19:54,179:INFO:Declaring metric variables
2024-08-31 23:19:54,180:INFO:Importing untrained model
2024-08-31 23:19:54,181:INFO:Linear Discriminant Analysis Imported successfully
2024-08-31 23:19:54,183:INFO:Starting cross validation
2024-08-31 23:19:54,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:54,261:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,274:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,276:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,278:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,279:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,286:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,304:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,315:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,317:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,325:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-08-31 23:19:54,328:INFO:Calculating mean and std
2024-08-31 23:19:54,328:INFO:Creating metrics dataframe
2024-08-31 23:19:54,329:INFO:Uploading results into container
2024-08-31 23:19:54,330:INFO:Uploading model into container now
2024-08-31 23:19:54,330:INFO:_master_model_container: 12
2024-08-31 23:19:54,330:INFO:_display_container: 2
2024-08-31 23:19:54,330:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-31 23:19:54,330:INFO:create_model() successfully completed......................................
2024-08-31 23:19:54,377:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:54,378:INFO:Creating metrics dataframe
2024-08-31 23:19:54,381:INFO:Initializing Extra Trees Classifier
2024-08-31 23:19:54,382:INFO:Total runtime is 0.11505388021469115 minutes
2024-08-31 23:19:54,383:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:54,383:INFO:Initializing create_model()
2024-08-31 23:19:54,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:54,383:INFO:Checking exceptions
2024-08-31 23:19:54,383:INFO:Importing libraries
2024-08-31 23:19:54,383:INFO:Copying training dataset
2024-08-31 23:19:54,385:INFO:Defining folds
2024-08-31 23:19:54,385:INFO:Declaring metric variables
2024-08-31 23:19:54,385:INFO:Importing untrained model
2024-08-31 23:19:54,387:INFO:Extra Trees Classifier Imported successfully
2024-08-31 23:19:54,388:INFO:Starting cross validation
2024-08-31 23:19:54,389:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:54,807:INFO:Calculating mean and std
2024-08-31 23:19:54,808:INFO:Creating metrics dataframe
2024-08-31 23:19:54,809:INFO:Uploading results into container
2024-08-31 23:19:54,809:INFO:Uploading model into container now
2024-08-31 23:19:54,810:INFO:_master_model_container: 13
2024-08-31 23:19:54,810:INFO:_display_container: 2
2024-08-31 23:19:54,810:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-31 23:19:54,810:INFO:create_model() successfully completed......................................
2024-08-31 23:19:54,857:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:54,857:INFO:Creating metrics dataframe
2024-08-31 23:19:54,861:INFO:Initializing Extreme Gradient Boosting
2024-08-31 23:19:54,861:INFO:Total runtime is 0.12304685115814208 minutes
2024-08-31 23:19:54,862:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:54,862:INFO:Initializing create_model()
2024-08-31 23:19:54,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:54,862:INFO:Checking exceptions
2024-08-31 23:19:54,863:INFO:Importing libraries
2024-08-31 23:19:54,863:INFO:Copying training dataset
2024-08-31 23:19:54,864:INFO:Defining folds
2024-08-31 23:19:54,864:INFO:Declaring metric variables
2024-08-31 23:19:54,865:INFO:Importing untrained model
2024-08-31 23:19:54,866:INFO:Extreme Gradient Boosting Imported successfully
2024-08-31 23:19:54,867:INFO:Starting cross validation
2024-08-31 23:19:54,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:19:55,282:INFO:Calculating mean and std
2024-08-31 23:19:55,283:INFO:Creating metrics dataframe
2024-08-31 23:19:55,284:INFO:Uploading results into container
2024-08-31 23:19:55,284:INFO:Uploading model into container now
2024-08-31 23:19:55,285:INFO:_master_model_container: 14
2024-08-31 23:19:55,285:INFO:_display_container: 2
2024-08-31 23:19:55,285:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-08-31 23:19:55,285:INFO:create_model() successfully completed......................................
2024-08-31 23:19:55,331:INFO:SubProcess create_model() end ==================================
2024-08-31 23:19:55,331:INFO:Creating metrics dataframe
2024-08-31 23:19:55,335:INFO:Initializing Light Gradient Boosting Machine
2024-08-31 23:19:55,336:INFO:Total runtime is 0.13095418214797971 minutes
2024-08-31 23:19:55,337:INFO:SubProcess create_model() called ==================================
2024-08-31 23:19:55,337:INFO:Initializing create_model()
2024-08-31 23:19:55,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:19:55,337:INFO:Checking exceptions
2024-08-31 23:19:55,337:INFO:Importing libraries
2024-08-31 23:19:55,337:INFO:Copying training dataset
2024-08-31 23:19:55,338:INFO:Defining folds
2024-08-31 23:19:55,338:INFO:Declaring metric variables
2024-08-31 23:19:55,339:INFO:Importing untrained model
2024-08-31 23:19:55,340:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-31 23:19:55,342:INFO:Starting cross validation
2024-08-31 23:19:55,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:20:14,848:INFO:Calculating mean and std
2024-08-31 23:20:14,849:INFO:Creating metrics dataframe
2024-08-31 23:20:14,850:INFO:Uploading results into container
2024-08-31 23:20:14,851:INFO:Uploading model into container now
2024-08-31 23:20:14,851:INFO:_master_model_container: 15
2024-08-31 23:20:14,851:INFO:_display_container: 2
2024-08-31 23:20:14,851:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-31 23:20:14,851:INFO:create_model() successfully completed......................................
2024-08-31 23:20:14,900:INFO:SubProcess create_model() end ==================================
2024-08-31 23:20:14,900:INFO:Creating metrics dataframe
2024-08-31 23:20:14,905:INFO:Initializing CatBoost Classifier
2024-08-31 23:20:14,905:INFO:Total runtime is 0.4571085969607035 minutes
2024-08-31 23:20:14,906:INFO:SubProcess create_model() called ==================================
2024-08-31 23:20:14,906:INFO:Initializing create_model()
2024-08-31 23:20:14,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:20:14,906:INFO:Checking exceptions
2024-08-31 23:20:14,906:INFO:Importing libraries
2024-08-31 23:20:14,906:INFO:Copying training dataset
2024-08-31 23:20:14,908:INFO:Defining folds
2024-08-31 23:20:14,908:INFO:Declaring metric variables
2024-08-31 23:20:14,909:INFO:Importing untrained model
2024-08-31 23:20:14,910:INFO:CatBoost Classifier Imported successfully
2024-08-31 23:20:14,912:INFO:Starting cross validation
2024-08-31 23:20:14,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:20:19,154:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,156:INFO:Calculating mean and std
2024-08-31 23:20:19,156:INFO:Creating metrics dataframe
2024-08-31 23:20:19,157:INFO:Uploading results into container
2024-08-31 23:20:19,158:INFO:Uploading model into container now
2024-08-31 23:20:19,158:INFO:_master_model_container: 16
2024-08-31 23:20:19,158:INFO:_display_container: 2
2024-08-31 23:20:19,158:INFO:<catboost.core.CatBoostClassifier object at 0x16c570690>
2024-08-31 23:20:19,158:INFO:create_model() successfully completed......................................
2024-08-31 23:20:19,204:INFO:SubProcess create_model() end ==================================
2024-08-31 23:20:19,204:INFO:Creating metrics dataframe
2024-08-31 23:20:19,208:INFO:Initializing Dummy Classifier
2024-08-31 23:20:19,209:INFO:Total runtime is 0.528836981455485 minutes
2024-08-31 23:20:19,210:INFO:SubProcess create_model() called ==================================
2024-08-31 23:20:19,210:INFO:Initializing create_model()
2024-08-31 23:20:19,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16d022410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:20:19,210:INFO:Checking exceptions
2024-08-31 23:20:19,210:INFO:Importing libraries
2024-08-31 23:20:19,210:INFO:Copying training dataset
2024-08-31 23:20:19,211:INFO:Defining folds
2024-08-31 23:20:19,211:INFO:Declaring metric variables
2024-08-31 23:20:19,212:INFO:Importing untrained model
2024-08-31 23:20:19,213:INFO:Dummy Classifier Imported successfully
2024-08-31 23:20:19,215:INFO:Starting cross validation
2024-08-31 23:20:19,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-31 23:20:19,283:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,303:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,305:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,307:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,318:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,332:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,334:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,341:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,351:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,362:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-31 23:20:19,364:INFO:Calculating mean and std
2024-08-31 23:20:19,366:INFO:Creating metrics dataframe
2024-08-31 23:20:19,367:INFO:Uploading results into container
2024-08-31 23:20:19,368:INFO:Uploading model into container now
2024-08-31 23:20:19,368:INFO:_master_model_container: 17
2024-08-31 23:20:19,368:INFO:_display_container: 2
2024-08-31 23:20:19,368:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-08-31 23:20:19,368:INFO:create_model() successfully completed......................................
2024-08-31 23:20:19,421:INFO:SubProcess create_model() end ==================================
2024-08-31 23:20:19,421:INFO:Creating metrics dataframe
2024-08-31 23:20:19,428:INFO:Initializing create_model()
2024-08-31 23:20:19,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x169d47d10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-31 23:20:19,429:INFO:Checking exceptions
2024-08-31 23:20:19,430:INFO:Importing libraries
2024-08-31 23:20:19,430:INFO:Copying training dataset
2024-08-31 23:20:19,431:INFO:Defining folds
2024-08-31 23:20:19,431:INFO:Declaring metric variables
2024-08-31 23:20:19,431:INFO:Importing untrained model
2024-08-31 23:20:19,431:INFO:Declaring custom model
2024-08-31 23:20:19,432:INFO:Logistic Regression Imported successfully
2024-08-31 23:20:19,432:INFO:Cross validation set to False
2024-08-31 23:20:19,432:INFO:Fitting Model
2024-08-31 23:20:19,612:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 23:20:19,612:INFO:create_model() successfully completed......................................
2024-08-31 23:20:19,665:INFO:_master_model_container: 17
2024-08-31 23:20:19,665:INFO:_display_container: 2
2024-08-31 23:20:19,666:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-31 23:20:19,666:INFO:compare_models() successfully completed......................................
2024-08-31 23:20:19,695:INFO:Initializing save_model()
2024-08-31 23:20:19,695:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-31 23:20:19,695:INFO:Adding model into prep_pipe
2024-08-31 23:20:19,699:INFO:student_performance_model.pkl saved in current working directory
2024-08-31 23:20:19,726:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Gender...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-08-31 23:20:19,726:INFO:save_model() successfully completed......................................
2024-08-31 23:20:19,802:INFO:Soft dependency imported: fastapi: 0.112.2
2024-08-31 23:20:19,803:INFO:Soft dependency imported: uvicorn: 0.30.6
2024-08-31 23:20:19,803:INFO:Soft dependency imported: pydantic: 1.10.8
2024-08-31 23:20:19,832:INFO:Initializing save_model()
2024-08-31 23:20:19,832:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=student_performance_api, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tw/qtbtb6ln3q17d50f36hzg22h0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-08-31 23:20:19,832:INFO:Adding model into prep_pipe
2024-08-31 23:20:19,836:INFO:student_performance_api.pkl saved in current working directory
2024-08-31 23:20:19,862:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Gender...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-08-31 23:20:19,862:INFO:save_model() successfully completed......................................
2024-08-31 23:24:11,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:24:11,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:24:11,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:24:11,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-31 23:24:11,984:INFO:Initializing load_model()
2024-08-31 23:24:11,984:INFO:load_model(model_name=student_performance_api, platform=None, authentication=None, verbose=True)
2024-08-31 23:24:12,091:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-08-31 23:37:24,087:INFO:Initializing predict_model()
2024-08-31 23:37:24,087:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x175e40110>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalSupport',
                                             'Extracurricular', 'Sports',
                                             'Music', 'Volunteering'],
                                    transformer=Simple...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x175e3cae0>)
2024-08-31 23:37:24,087:INFO:Checking exceptions
2024-08-31 23:37:24,087:INFO:Preloading libraries
2024-08-31 23:37:24,090:INFO:Set up data.
2024-08-31 23:37:24,095:INFO:Set up index.
2024-09-02 20:26:51,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:26:51,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:26:51,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:26:51,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:38:42,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:38:42,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:38:42,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:38:42,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-02 20:38:43,060:INFO:Initializing load_model()
2024-09-02 20:38:43,060:INFO:load_model(model_name=student_performance_api, platform=None, authentication=None, verbose=True)
2024-09-02 20:38:43,275:WARNING:/Users/fady/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.
  warnings.warn(

2024-09-02 20:40:43,365:INFO:Initializing predict_model()
2024-09-02 20:40:43,366:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16fa4d890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalSupport',
                                             'Extracurricular', 'Sports',
                                             'Music', 'Volunteering'],
                                    transformer=Simple...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x17abf84a0>)
2024-09-02 20:40:43,366:INFO:Checking exceptions
2024-09-02 20:40:43,366:INFO:Preloading libraries
2024-09-02 20:40:43,368:INFO:Set up data.
2024-09-02 20:40:43,372:INFO:Set up index.
